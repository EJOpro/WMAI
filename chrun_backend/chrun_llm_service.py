"""
LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ ì•¡ì…˜ ìƒì„± ì„œë¹„ìŠ¤
"""
import os
import json
from typing import Dict, List, Optional
from datetime import datetime
from decimal import Decimal
import openai
from openai import OpenAI
import logging
import pathlib
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (chrun_backend í´ë”ì˜ .env íŒŒì¼ ìš°ì„  ë¡œë“œ)
current_dir = pathlib.Path(__file__).parent
env_path = current_dir / '.env'
if env_path.exists():
    load_dotenv(env_path)
    print(f"[INFO] LLM ì„œë¹„ìŠ¤: .env íŒŒì¼ ë¡œë“œë¨: {env_path}")
else:
    load_dotenv()  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ì‹œë„
    print("[INFO] LLM ì„œë¹„ìŠ¤: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ë¡œë“œ ì‹œë„")

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class LLMInsightGenerator:
    """LLMì„ í™œìš©í•œ ì´íƒˆ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.client = None
        self.model = "gpt-4o-mini"  # ê¸°ë³¸ ëª¨ë¸ (ìºì‹œ í‚¤ì— ì‚¬ìš©)
        self.prompt_version = "v1"  # í”„ë¡¬í”„íŠ¸ ë²„ì „ (ìºì‹œ í‚¤ì— ì‚¬ìš©)
        self._initialize_client()
    
    def _initialize_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        
        # ë””ë²„ê¹… ì •ë³´
        print(f"[DEBUG] OPENAI_API_KEY í™•ì¸: {'ì„¤ì •ë¨' if api_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
        if api_key:
            print(f"[DEBUG] API í‚¤ ì• 10ìë¦¬: {api_key[:10]}...")
        
        if not api_key:
            logger.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            print("[WARNING] OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            print("[INFO] AI ì¸ì‚¬ì´íŠ¸ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ OPENAI_SETUP_GUIDE.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")
            return
        
        try:
            self.client = OpenAI(api_key=api_key)
            logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            print("[INFO] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print(f"[ERROR] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def generate_insights_and_actions(self, analysis_data: Dict) -> Dict[str, List[str]]:
        """
        ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ í†µí•´ ì¸ì‚¬ì´íŠ¸ì™€ ê¶Œì¥ ì•¡ì…˜ ìƒì„±
        
        Args:
            analysis_data: ì´íƒˆ ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            
        Returns:
            Dict containing 'insights' and 'actions' lists
        """
        print(f"[DEBUG] LLM generate_insights_and_actions í˜¸ì¶œë¨")
        print(f"[DEBUG] OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ: {'ì´ˆê¸°í™”ë¨' if self.client else 'ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ'}")
        
        if not self.client:
            logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            print("[WARNING] OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. Fallback ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
            return self._generate_fallback_insights(analysis_data)
        
        try:
            print("[INFO] LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘ - ë°ì´í„° ìš”ì•½ ìƒì„± ì¤‘...")
            # ë°ì´í„° ìš”ì•½ ìƒì„±
            data_summary = self._create_data_summary(analysis_data)
            print(f"[INFO] ë°ì´í„° ìš”ì•½ ìƒì„± ì™„ë£Œ - ì„¸ê·¸ë¨¼íŠ¸: {len(data_summary.get('ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„', {}))}ê°œ")
            
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_analysis_prompt(data_summary)
            print(f"[INFO] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(prompt)}ì")
            
            # OpenAI API í˜¸ì¶œ
            print("[INFO] OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
                max_tokens=1500
            )
            
            # ì‘ë‹µ íŒŒì‹±
            print("[INFO] OpenAI API ì‘ë‹µ ìˆ˜ì‹  - íŒŒì‹± ì¤‘...")
            result = json.loads(response.choices[0].message.content)
            print(f"[INFO] íŒŒì‹± ì™„ë£Œ - insights: {len(result.get('insights', []))}ê°œ, actions: {len(result.get('actions', []))}ê°œ")
            
            # ê²°ê³¼ ê²€ì¦ ë° ì •ì œ
            insights = result.get('insights', [])[:3]  # ìµœëŒ€ 3ê°œ
            actions = result.get('actions', [])[:3]    # ìµœëŒ€ 3ê°œ
            
            # ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦
            insights = self._filter_and_validate_responses(insights, 'insights')
            actions = self._filter_and_validate_responses(actions, 'actions')
            
            print(f"[INFO] í•„í„°ë§ ì™„ë£Œ - ìµœì¢… insights: {len(insights)}ê°œ, actions: {len(actions)}ê°œ")
            logger.info(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸, {len(actions)}ê°œ ì•¡ì…˜")
            
            return {
                'insights': insights,
                'actions': actions,
                'generated_by': 'llm',
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._generate_fallback_insights(analysis_data)
    
    def _get_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜"""
        return """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì´íƒˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ ê¶Œì¥ ì•¡ì…˜ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì‘ë‹µ ê·œì¹™:
1. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: {"insights": [...], "actions": [...]}
2. ì¸ì‚¬ì´íŠ¸ëŠ” ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œë¥¼ ì„¤ëª…
3. ê¶Œì¥ ì•¡ì…˜ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ ì œì‹œ
4. ê°ê° ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì œê³µ
5. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ë°˜ë“œì‹œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
6. ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ê²½ìš° "Uncertain" í‘œê¸°
7. í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì°¨ì´(5%p ì´ìƒ)ë§Œ ì–¸ê¸‰

ë¶„ì„ ê´€ì :
- ì„¸ê·¸ë¨¼íŠ¸ë³„ ì´íƒˆë¥  ì°¨ì´
- ì‹œê°„ë³„ íŠ¸ë Œë“œ ë³€í™”
- ì¬í™œì„±í™” íŒ¨í„´
- ìœ„í—˜ ì‚¬ìš©ì ê·¸ë£¹
- ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ

ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤:
- ì¶”ì¸¡ì´ë‚˜ ê°€ì •ì— ê¸°ë°˜í•œ ë¶„ì„ ê¸ˆì§€
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ë¥¼ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê°œì¸ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ ì–¸ê¸‰ ê¸ˆì§€
- ë¹„ìœ¤ë¦¬ì ì´ê±°ë‚˜ ì°¨ë³„ì ì¸ ê¶Œì¥ì‚¬í•­ ì œì‹œ ê¸ˆì§€
- ë²•ì  ì¡°ì–¸ì´ë‚˜ ì˜ë£Œì  ì¡°ì–¸ ì œê³µ ê¸ˆì§€
- ë§ˆì¼€íŒ…ì´ë‚˜ ì˜ì—… ëª©ì ì˜ ê³¼ì¥ëœ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì–¸ê¸‰ ê¸ˆì§€
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ì°¨ì´ë¥¼ ê³¼ì¥í•˜ì—¬ ì„¤ëª… ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ë°ì´í„°ë¥¼ í™•ì‹¤í•œ ê²ƒì²˜ëŸ¼ í‘œí˜„ ê¸ˆì§€"""

    def _convert_decimal(self, value):
        """Decimal íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        if isinstance(value, Decimal):
            return float(value)
        elif isinstance(value, (int, float)):
            return value
        elif value is None:
            return 0
        else:
            try:
                return float(value)
            except (ValueError, TypeError):
                return value
    
    def _create_data_summary(self, analysis_data: Dict) -> Dict:
        """ë¶„ì„ ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ìš”ì•½"""
        
        summary = {
            "ê¸°ë³¸_ì§€í‘œ": {},
            "ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„": {},
            "íŠ¸ë Œë“œ_ë¶„ì„": {},
            "ë°ì´í„°_í’ˆì§ˆ": {},
            "ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸": {}
        }
        
        # ê¸°ë³¸ ì§€í‘œ ìš”ì•½
        metrics = analysis_data.get('metrics', {})
        churn_rate = self._convert_decimal(metrics.get('churn_rate', 0))
        active_users = int(self._convert_decimal(metrics.get('active_users', 0)))
        reactivated_users = int(self._convert_decimal(metrics.get('reactivated_users', 0)))
        long_term_inactive = int(self._convert_decimal(metrics.get('long_term_inactive', 0)))
        
        summary["ê¸°ë³¸_ì§€í‘œ"] = {
            "ì „ì²´_ì´íƒˆë¥ ": f"{churn_rate:.1f}%",
            "í™œì„±_ì‚¬ìš©ì": active_users,
            "ì¬í™œì„±_ì‚¬ìš©ì": reactivated_users,
            "ì¥ê¸°_ë¯¸ì ‘ì†": long_term_inactive,
            "ë¶„ì„_ê¸°ê°„": f"{analysis_data.get('start_month', 'N/A')} ~ {analysis_data.get('end_month', 'N/A')}"
        }
        
        # ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ê°€
        config = analysis_data.get('config', {})
        selected_segments = config.get('segments', {})
        summary["ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸"] = {
            "ì„±ë³„_ë¶„ì„": selected_segments.get('gender', False),
            "ì—°ë ¹ëŒ€_ë¶„ì„": selected_segments.get('age_band', False),
            "ì±„ë„_ë¶„ì„": selected_segments.get('channel', False)
        }
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ìš”ì•½ (ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ)
        segments = analysis_data.get('segments', {})
        segment_names = {
            'gender': 'ì„±ë³„',
            'age_band': 'ì—°ë ¹ëŒ€', 
            'channel': 'ì±„ë„'
        }
        
        for segment_type, segment_data in segments.items():
            if segment_data and selected_segments.get(segment_type, False):
                segment_summary = []
                for item in segment_data:
                    item_churn_rate = self._convert_decimal(item.get('churn_rate', 0))
                    item_active = int(self._convert_decimal(item.get('current_active', 0)))
                    segment_summary.append({
                        "ê·¸ë£¹": item.get('segment_value', 'Unknown'),
                        "ì´íƒˆë¥ ": f"{item_churn_rate:.1f}%",
                        "í™œì„±ì‚¬ìš©ì": item_active,
                        "ì‹ ë¢°ë„": "Uncertain" if item.get('is_uncertain', False) else "í™•ì‹¤"
                    })
                summary["ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„"][segment_names.get(segment_type, segment_type)] = segment_summary
        
        # íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½
        trends = analysis_data.get('trends', {})
        if trends:
            trend_data = trends.get('monthly_churn_rates', [])
            if len(trend_data) >= 2:
                first_rate = self._convert_decimal(trend_data[0].get('churn_rate', 0))
                last_rate = self._convert_decimal(trend_data[-1].get('churn_rate', 0))
                change = last_rate - first_rate
                
                summary["íŠ¸ë Œë“œ_ë¶„ì„"] = {
                    "ê¸°ê°„": f"{len(trend_data)}ê°œì›”",
                    "ì‹œì‘_ì´íƒˆë¥ ": f"{first_rate:.1f}%",
                    "ìµœì¢…_ì´íƒˆë¥ ": f"{last_rate:.1f}%",
                    "ë³€í™”ëŸ‰": f"{change:+.1f}%p",
                    "íŠ¸ë Œë“œ": "ìƒìŠ¹" if change > 1 else "í•˜ë½" if change < -1 else "ì•ˆì •"
                }
        
        # ë°ì´í„° í’ˆì§ˆ ìš”ì•½
        quality = analysis_data.get('data_quality', {})
        total_events = int(self._convert_decimal(quality.get('total_events', 0)))
        valid_events = int(self._convert_decimal(quality.get('valid_events', 0)))
        completeness = self._convert_decimal(quality.get('data_completeness', 0))
        unknown_ratio = self._convert_decimal(quality.get('unknown_ratio', 0))
        
        summary["ë°ì´í„°_í’ˆì§ˆ"] = {
            "ì´_ì´ë²¤íŠ¸": total_events,
            "ìœ íš¨_ì´ë²¤íŠ¸": valid_events,
            "ì™„ì „ì„±": f"{completeness:.1f}%",
            "ì•Œìˆ˜ì—†ìŒ_ë¹„ìœ¨": f"{unknown_ratio:.1f}%"
        }
        
        return summary
    
    def _create_analysis_prompt(self, data_summary: Dict) -> str:
        """LLM ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ í™•ì¸
        selected_segments = data_summary.get('ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸', {})
        segment_analysis_available = any(selected_segments.values())
        
        prompt = f"""ë‹¤ìŒ ì´íƒˆ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3ê°œì™€ ê¶Œì¥ ì•¡ì…˜ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ì„¤ì •

### ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸
{json.dumps(data_summary['ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸'], ensure_ascii=False, indent=2)}

## ë¶„ì„ ë°ì´í„°

### ê¸°ë³¸ ì§€í‘œ
{json.dumps(data_summary['ê¸°ë³¸_ì§€í‘œ'], ensure_ascii=False, indent=2)}"""

        # ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ì´ ìˆëŠ” ê²½ìš°ë§Œ í¬í•¨
        if segment_analysis_available and data_summary['ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„']:
            prompt += f"""

### ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„ (ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ)
{json.dumps(data_summary['ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„'], ensure_ascii=False, indent=2)}"""
        else:
            prompt += """

### ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„
ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì²´ ì‚¬ìš©ì ê¸°ì¤€ìœ¼ë¡œë§Œ ë¶„ì„í•˜ì„¸ìš”."""

        prompt += f"""

### íŠ¸ë Œë“œ ë¶„ì„
{json.dumps(data_summary['íŠ¸ë Œë“œ_ë¶„ì„'], ensure_ascii=False, indent=2)}

### ë°ì´í„° í’ˆì§ˆ
{json.dumps(data_summary['ë°ì´í„°_í’ˆì§ˆ'], ensure_ascii=False, indent=2)}

## ìš”ì²­ì‚¬í•­

1. **ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3ê°œ**: ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ ë¬¸ì œì ì„ ì¡´ëŒ“ë§ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
2. **ê¶Œì¥ ì•¡ì…˜ 3ê°œ**: ì´íƒˆë¥  ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ì•ˆì„ ì¡´ëŒ“ë§ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”

ì£¼ì˜ì‚¬í•­:
- ë°˜ë“œì‹œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸(ì„±ë³„/ì—°ë ¹ëŒ€/ì±„ë„)ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´(5%p ì´ìƒ)ë§Œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”
- ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì„¸ê·¸ë¨¼íŠ¸ëŠ” "Uncertain" í‘œê¸°í•´ì£¼ì„¸ìš”
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”
- ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ì„ ì œì‹œí•´ì£¼ì„¸ìš”

ê¸ˆì§€ì‚¬í•­:
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ì¸¡í•˜ê±°ë‚˜ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”
- ê°œì¸ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì°¨ë³„ì ì´ê±°ë‚˜ í¸í–¥ëœ ë¶„ì„ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
- ë²•ì  ì¡°ì–¸ì´ë‚˜ ì˜ë£Œì  ì¡°ì–¸ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
- ê³¼ì¥ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë°ì´í„°ë¥¼ ì„ì˜ë¡œ í•´ì„í•˜ì§€ ë§ˆì„¸ìš”
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ì°¨ì´ë¥¼ ê³¼ì¥í•˜ì—¬ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë°ì´í„°ë¥¼ í™•ì‹¤í•œ ê²ƒì²˜ëŸ¼ í‘œí˜„í•˜ì§€ ë§ˆì„¸ìš”"""

        return prompt
    
    def _filter_and_validate_responses(self, responses: List[str], response_type: str) -> List[str]:
        """ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦"""
        if not responses:
            return []
        
        filtered_responses = []
        prohibited_terms = [
            'ê°œì¸ì •ë³´', 'ë¯¼ê°ì •ë³´', 'ë²•ì ', 'ì˜ë£Œ', 'ì°¨ë³„', 'í¸í–¥', 
            'ì¶”ì¸¡', 'ê°€ì •', 'í™•ì‹¤í•˜ì§€', 'ë¶ˆí™•ì‹¤', 'ê³¼ì¥'
        ]
        
        for response in responses:
            if not isinstance(response, str) or len(response.strip()) == 0:
                continue
                
            # ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ ì‘ë‹µ í•„í„°ë§
            if any(term in response for term in prohibited_terms):
                logger.warning(f"ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ {response_type} ì‘ë‹µ í•„í„°ë§: {response[:50]}...")
                continue
            
            # ì‘ë‹µ ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì‘ë‹µ ì œì™¸)
            if len(response) < 10 or len(response) > 500:
                logger.warning(f"ë¶€ì ì ˆí•œ ê¸¸ì´ì˜ {response_type} ì‘ë‹µ í•„í„°ë§: {len(response)}ì")
                continue
            
            # ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì¦ í†µê³¼
            filtered_responses.append(response.strip())
        
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        return filtered_responses[:3]
    
    def _generate_fallback_insights(self, analysis_data: Dict) -> Dict[str, List[str]]:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê¸°ë³¸ ë¶„ì„ ì œê³µ"""
        
        # ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = []
        actions = []
        
        try:
            # ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ
            metrics = analysis_data.get('metrics', {})
            segments = analysis_data.get('segments', {})
            trends = analysis_data.get('trends', {})
            data_quality = analysis_data.get('data_quality', {})
            
            # 1. ì „ì²´ ì´íƒˆë¥  ì¸ì‚¬ì´íŠ¸
            churn_rate = metrics.get('churn_rate', 0)
            active_users = metrics.get('active_users', 0)
            
            if churn_rate > 25:
                insights.append(f"âš ï¸ ì „ì²´ ì´íƒˆë¥ ì´ {churn_rate:.1f}%ë¡œ ë§¤ìš° ë†’ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì¦‰ì‹œ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                actions.append("ğŸš¨ ê¸´ê¸‰ ì´íƒˆ ë°©ì§€ í”„ë¡œê·¸ë¨ ë„ì… ë° ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘")
            elif churn_rate > 15:
                insights.append(f"ğŸ“Š ì „ì²´ ì´íƒˆë¥ ì´ {churn_rate:.1f}%ë¡œ ì£¼ì˜ê°€ í•„ìš”í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
                actions.append("ğŸ“‹ ì´íƒˆ ìœ„í—˜ ì‚¬ìš©ì ì‹ë³„ ë° ë§ì¶¤í˜• ë¦¬í…ì…˜ ìº í˜ì¸ ì‹¤í–‰")
            elif churn_rate > 5:
                insights.append(f"âœ… ì „ì²´ ì´íƒˆë¥ ì´ {churn_rate:.1f}%ë¡œ ì–‘í˜¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
                actions.append("âœ¨ í˜„ì¬ ì„œë¹„ìŠ¤ í’ˆì§ˆ ìœ ì§€ ë° ì‚¬ìš©ì ë§Œì¡±ë„ ì§€ì† ëª¨ë‹ˆí„°ë§")
            else:
                insights.append(f"ğŸ‰ ì „ì²´ ì´íƒˆë¥ ì´ {churn_rate:.1f}%ë¡œ ë§¤ìš° ìš°ìˆ˜í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
                actions.append("ğŸ† ìš°ìˆ˜í•œ ë¦¬í…ì…˜ ì „ëµì„ ë‹¤ë¥¸ ì„¸ê·¸ë¨¼íŠ¸ì—ë„ í™•ëŒ€ ì ìš©")
            
            # 2. í™œì„± ì‚¬ìš©ì íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸
            previous_users = metrics.get('previous_active_users', 0)
            if previous_users > 0:
                growth = ((active_users - previous_users) / previous_users * 100)
                if growth > 10:
                    insights.append(f"ğŸ“ˆ í™œì„± ì‚¬ìš©ìê°€ {active_users:,}ëª…ìœ¼ë¡œ {growth:.1f}% ê¸‰ì„±ì¥í–ˆìŠµë‹ˆë‹¤.")
                    actions.append("ğŸš€ ì„±ì¥ ë™ë ¥ì„ ë¶„ì„í•˜ì—¬ ì„±ê³µ ìš”ì¸ì„ ë‹¤ë¥¸ ì˜ì—­ì— ì ìš©")
                elif growth > 0:
                    insights.append(f"ğŸ“Š í™œì„± ì‚¬ìš©ìê°€ {active_users:,}ëª…ìœ¼ë¡œ {growth:.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
                    actions.append("ğŸ“ˆ ì„±ì¥ì„¸ ìœ ì§€ë¥¼ ìœ„í•œ ì‚¬ìš©ì ê²½í—˜ ê°œì„  ì§€ì†")
                elif growth > -10:
                    insights.append(f"ğŸ“‰ í™œì„± ì‚¬ìš©ìê°€ {active_users:,}ëª…ìœ¼ë¡œ {abs(growth):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")
                    actions.append("ğŸ” ì‚¬ìš©ì ê°ì†Œ ì›ì¸ ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½")
                else:
                    insights.append(f"âš ï¸ í™œì„± ì‚¬ìš©ìê°€ {active_users:,}ëª…ìœ¼ë¡œ {abs(growth):.1f}% ê¸‰ê°í–ˆìŠµë‹ˆë‹¤.")
                    actions.append("ğŸš¨ ê¸´ê¸‰ ì‚¬ìš©ì ë³µê·€ ìº í˜ì¸ ë° ì„œë¹„ìŠ¤ ê°œì„  í•„ìš”")
            
            # 3. ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (ê°€ì¥ ë†’ì€ ì´íƒˆë¥  ì„¸ê·¸ë¨¼íŠ¸)
            highest_churn_segment = None
            highest_churn_rate = 0
            segment_type_name = ""
            
            for seg_type, seg_data in segments.items():
                if seg_data and isinstance(seg_data, list) and len(seg_data) > 0:
                    for segment in seg_data:
                        if segment.get('churn_rate', 0) > highest_churn_rate:
                            highest_churn_rate = segment.get('churn_rate', 0)
                            highest_churn_segment = segment
                            segment_type_name = seg_type
            
            if highest_churn_segment and highest_churn_rate > 15:
                segment_names = {
                    'gender': {'M': 'ë‚¨ì„±', 'F': 'ì—¬ì„±'},
                    'age_band': {'10s': '10ëŒ€', '20s': '20ëŒ€', '30s': '30ëŒ€', '40s': '40ëŒ€', '50s': '50ëŒ€', '60s': '60ëŒ€'},
                    'channel': {'web': 'ì›¹', 'app': 'ëª¨ë°”ì¼ ì•±'}
                }
                
                segment_display = segment_names.get(segment_type_name, {}).get(
                    highest_churn_segment['segment_value'], 
                    highest_churn_segment['segment_value']
                )
                
                uncertain_note = " (ëª¨ìˆ˜ ë¶€ì¡±)" if highest_churn_segment.get('is_uncertain', False) else ""
                insights.append(f"ğŸ¯ {segment_display} ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë†’ì€ ì´íƒˆë¥ ({highest_churn_rate:.1f}%)ì„ ë³´ì…ë‹ˆë‹¤{uncertain_note}.")
                
                # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤ ì•¡ì…˜
                if segment_type_name == 'gender':
                    if highest_churn_segment['segment_value'] == 'F':
                        actions.append("ğŸ‘¥ ì—¬ì„± ì‚¬ìš©ì ëŒ€ìƒ ë§ì¶¤í˜• ì½˜í…ì¸  ë° ì»¤ë®¤ë‹ˆí‹° í™œë™ ê°•í™”")
                    else:
                        actions.append("ğŸ‘¥ ë‚¨ì„± ì‚¬ìš©ì ëŒ€ìƒ ë§ì¶¤í˜• ì„œë¹„ìŠ¤ ë° ê¸°ëŠ¥ ê°œì„ ")
                elif segment_type_name == 'age_band':
                    if highest_churn_segment['segment_value'] in ['50s', '60s']:
                        actions.append("ğŸ‘´ 50ëŒ€ ì´ìƒ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì‚¬ìš©ì„± ê°œì„  ë° ì‹ ê·œ ê°€ì´ë“œ ì œê³µ")
                    elif highest_churn_segment['segment_value'] in ['10s', '20s']:
                        actions.append("ğŸ‘¶ ì Šì€ ì‚¬ìš©ìì¸µì„ ìœ„í•œ íŠ¸ë Œë””í•œ ì½˜í…ì¸  ë° ì†Œì…œ ê¸°ëŠ¥ ê°•í™”")
                    else:
                        actions.append(f"ğŸ¯ {segment_display} ì—°ë ¹ëŒ€ë¥¼ ìœ„í•œ ì „ìš© ì„œë¹„ìŠ¤ ë° UI/UX ê°œì„ ")
                elif segment_type_name == 'channel':
                    if highest_churn_segment['segment_value'] == 'app':
                        actions.append("ğŸ“± ëª¨ë°”ì¼ ì•± ì‚¬ìš©ì ê²½í—˜ ê°œì„  ë° í‘¸ì‹œ ì•Œë¦¼ ìµœì í™”")
                    else:
                        actions.append("ğŸ’» ì›¹ í”Œë«í¼ ì‚¬ìš©ì ê²½í—˜ ê°œì„  ë° ê¸°ëŠ¥ ìµœì í™”")
            
            # 4. ì¥ê¸° ë¯¸ì ‘ì† ì‚¬ìš©ì ì¸ì‚¬ì´íŠ¸
            long_term_inactive = metrics.get('long_term_inactive', 0)
            if long_term_inactive > 0 and active_users > 0:
                inactive_ratio = (long_term_inactive / (active_users + long_term_inactive)) * 100
                if inactive_ratio > 15:
                    insights.append(f"â³ ì¥ê¸° ë¯¸ì ‘ì† ì‚¬ìš©ìê°€ ì „ì²´ì˜ {inactive_ratio:.1f}%ë¡œ ë†’ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
                    actions.append("ğŸ”„ ì¥ê¸° ë¯¸ì ‘ì†ì ëŒ€ìƒ ë³µê·€ ìœ ë„ ìº í˜ì¸ ë° ê°œì¸í™”ëœ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•")
            
            # 5. ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if data_quality:
                completeness = data_quality.get('data_completeness', 100)
                if completeness < 90:
                    insights.append(f"ğŸ“Š ë°ì´í„° ì™„ì „ì„±ì´ {completeness:.1f}%ë¡œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    actions.append("ğŸ”§ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ê°œì„  ë° í’ˆì§ˆ ê´€ë¦¬ ê°•í™”")
            
            # ì¸ì‚¬ì´íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ì¶”ê°€
            if len(insights) == 0:
                insights.append("ğŸ“Š í˜„ì¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ë³¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            if len(actions) == 0:
                actions.append("ğŸ“ˆ ì§€ì†ì ì¸ ì‚¬ìš©ì í–‰ë™ ëª¨ë‹ˆí„°ë§ ë° ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ìˆ˜í–‰")
            
            # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ë°˜í™˜
            insights = insights[:3]
            actions = actions[:3]
            
            # AI ë¶„ì„ ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€ (ë§ˆì§€ë§‰ì—)
            if len(insights) < 3:
                insights.append("ğŸ¤– OpenAI API í‚¤ ì„¤ì • ì‹œ ë” ì •í™•í•˜ê³  ìƒì„¸í•œ AI ë¶„ì„ì„ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if len(actions) < 3:
                actions.append("âš™ï¸ AI ê¸°ë°˜ ê¶Œì¥ ì•¡ì…˜ í™œì„±í™”ë¥¼ ìœ„í•´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìµœì†Œí•œì˜ ë©”ì‹œì§€
            insights = [
                "ğŸ“Š ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.",
                "ğŸ” ë” ìƒì„¸í•œ ë¶„ì„ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”.",
                "ğŸ¤– AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´ OpenAI API í‚¤ ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            ]
            actions = [
                "ğŸ“ˆ ì •ê¸°ì ì¸ ì´íƒˆë¥  ëª¨ë‹ˆí„°ë§ ë° íŠ¸ë Œë“œ ë¶„ì„ ìˆ˜í–‰",
                "ğŸ‘¥ ì£¼ìš” ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤í˜• ì „ëµ ìˆ˜ë¦½",
                "ğŸ”‘ OpenAI API í‚¤ ì„¤ì •ìœ¼ë¡œ AI ê¸°ë°˜ ë¶„ì„ í™œì„±í™”"
            ]
        
        return {
            'insights': insights,
            'actions': actions,
            'generated_by': 'basic_analysis',
            'timestamp': datetime.now().isoformat(),
            'setup_required': False,
            'data_driven': True
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
llm_generator = LLMInsightGenerator()
