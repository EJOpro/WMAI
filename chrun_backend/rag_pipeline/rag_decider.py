"""
RAG ê¸°ë°˜ ìœ„í—˜ë„ ê²°ì • ëª¨ë“ˆ

ì»¨í…ìŠ¤íŠ¸(evidence ë“±)ë¥¼ ì‚¬ìš©í•´ LLMì´ ìµœì¢… ìœ„í—˜ë„ì™€ ì•¡ì…˜ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ê°•ì œí•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
"""

import os
import json
import logging
import time
from typing import Dict, Any, List, Optional, Tuple
from dotenv import load_dotenv

from .report_schema import (
    create_report_schema,
    validate_report_schema,
    DEFAULT_MODEL as REPORT_DEFAULT_MODEL,
    PROMPT_VERSION as REPORT_PROMPT_VERSION,
)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì • ìƒìˆ˜
LLM_MODEL = "gpt-4o-mini"  # ë¹ ë¥´ê³  ê²½ì œì ì¸ ëª¨ë¸ ì‚¬ìš©
LLM_TIMEOUT = 30  # API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
MAX_TOKENS = 500  # ìµœëŒ€ í† í° ìˆ˜ (JSON ì‘ë‹µìš©)
TEMPERATURE = 0.1  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ëœ ê²°ê³¼

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


def decide_with_rag(context: Dict[str, Any]) -> Dict[str, Any]:
    """
    RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ìµœì¢… ìœ„í—˜ë„ì™€ ì•¡ì…˜ì„ ê²°ì •í•©ë‹ˆë‹¤.
    
    Args:
        context (Dict[str, Any]): check_new_postì—ì„œ ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        Dict[str, Any]: LLM ê²°ì • ê²°ê³¼
        {
            "risk_score": float,        # 0.0 ~ 1.0
            "priority": str,            # "LOW", "MEDIUM", "HIGH"
            "reasons": List[str],       # ìœ„í—˜ë„ íŒë‹¨ ì´ìœ  2~4ê°œ
            "actions": List[str],       # ê¶Œì¥ ì•¡ì…˜ 2~4ê°œ
            "evidence_ids": List[str]   # ì°¸ê³ í•œ evidence IDë“¤
        }
    """
    
    logger.info("LLM ê¸°ë°˜ ìœ„í—˜ë„ ê²°ì • ì‹œì‘")
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        logger.warning("[RAG] OPENAI_API_KEY ë¯¸ì„¤ì •, ê·œì¹™ ê¸°ë°˜ í´ë°±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return _finalize_decision(_get_fallback_decision(context, error="missing_openai_api_key"), context)
    
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ import ë° ì´ˆê¸°í™”
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("[RAG] OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í´ë°± ê²°ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return _finalize_decision(_get_fallback_decision(context, error="openai_package_missing"), context)
        
        logger.info("[RAG] OPENAI_API_KEY í™•ì¸ ì™„ë£Œ, LLM í˜¸ì¶œ ì¤€ë¹„ (timeout=%ss)", LLM_TIMEOUT)
        
        client = OpenAI(api_key=api_key, timeout=LLM_TIMEOUT)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = _create_system_prompt()
        user_prompt = _create_user_prompt(context)
        
        logger.debug(f"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(system_prompt)}")
        logger.debug(f"ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(user_prompt)}")
        
        # LLM API í˜¸ì¶œ
        try:
            llm_start = time.perf_counter()
            response = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE,
                response_format={"type": "json_object"}  # JSON í˜•ì‹ ê°•ì œ
            )
            llm_elapsed = (time.perf_counter() - llm_start) * 1000
            logger.info("[RAG] LLM íŒì • í˜¸ì¶œ ì™„ë£Œ (%.2f ms)", llm_elapsed)
        except Exception as call_error:
            if _is_timeout_error(call_error):
                logger.error("[RAG] LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ë°œìƒ (%ss)", LLM_TIMEOUT, exc_info=True)
                return _finalize_decision(_get_fallback_decision(context, error="llm_timeout"), context)
            raise
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response_text = response.choices[0].message.content.strip()
        logger.debug(f"LLM ì‘ë‹µ: {response_text}")
        
        # JSON íŒŒì‹±
        decision = _parse_llm_response(response_text, context)
        
        logger.info(f"LLM ê²°ì • ì™„ë£Œ: risk_score={decision.get('risk_score')}, priority={decision.get('priority')}")
        
        return _finalize_decision(decision, context)
        
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return _finalize_decision(_get_fallback_decision(context, error=str(e)), context)


def _create_system_prompt() -> str:
    """
    ì»¤ë®¤ë‹ˆí‹° íŠ¹í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ê´€ê³„ ê¸°ë°˜ ì´íƒˆ ë‹¨ê³„ ë¶„ì„ ëª¨ë¸ ì ìš©.
    
    Returns:
        str: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    """
    return """ë„ˆëŠ” ì»¤ë®¤ë‹ˆí‹° ì´íƒˆ ì§•í›„ ê°ì§€ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.

ì»¤ë®¤ë‹ˆí‹°ëŠ” ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ **ì‚¬ëŒê³¼ ì†Œì†ê°** ë•Œë¬¸ì— ìœ ì§€ëœë‹¤.
ê´€ê³„ ë‹¨ì ˆ ì‹ í˜¸ë¥¼ ì¡°ê¸°ì— í¬ì°©í•˜ê³ , íšŒë³µ ê°€ëŠ¥í•œ ë‹¨ê³„ì—ì„œ ê°œì…í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤.

**í•µì‹¬ ì›ì¹™:**
1. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•œë‹¤. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.
2. ì§€ì •ëœ ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ë”°ë¥¸ë‹¤.
3. í•œêµ­ì–´ë¡œ ì´ìœ ì™€ ì•¡ì…˜ì„ ì‘ì„±í•œë‹¤.
4. ëŒ€ìƒì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê°ì • í‘œí˜„ì€ ì¼ë°˜ì  ê°ì •ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ìœ„í—˜ë„ë¥¼ ë‚®ì¶˜ë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ì»¤ë®¤ë‹ˆí‹° ì´íƒˆ 5ë‹¨ê³„ ëª¨ë¸ (í•„ìˆ˜ ë¶„ë¥˜)**

[1ë‹¨ê³„: í™œë°œ ì°¸ì—¬ (Active)]
   ì‹ í˜¸: "ì¬ë¯¸ìˆì–´ìš”", "ì¢‹ì€ ê¸€", "ìš°ë¦¬ ì»¤ë®¤ë‹ˆí‹°", ì ê·¹ì  ëŒ“ê¸€/ì¢‹ì•„ìš”
   ì†Œì†ê°: ê°•í•¨ | ìœ„í—˜ë„: 0.0-0.15
   
[2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬ (Passive)]
   ì‹ í˜¸: ì¡°íšŒë§Œ í•¨, ì§§ì€ ë°˜ì‘, "ê·¸ëƒ¥ ë´ìš”", "ê°€ë” ë“¤ì–´ì™€ìš”"
   ì†Œì†ê°: ë³´í†µ | ìœ„í—˜ë„: 0.15-0.35
   
[3ë‹¨ê³„: ê´€ê³„ ë‹¨ì ˆ (Disconnect)] ** ê³¨ë“  íƒ€ì„!
   ì‹ í˜¸: "ì—¬ê¸° ì‚¬ëŒë“¤ ë³„ë¡œ", "ì†Œí†µ ì•ˆë¼ìš”", "í˜¼ì ê°™ì•„ìš”", "ì˜ˆì „ê°™ì§€ ì•Šë„¤ìš”"
   ì†Œì†ê°: ì•½í•¨ | ìœ„í—˜ë„: 0.35-0.60
   NOTE: ì´ ë‹¨ê³„ì—ì„œ ê°œì…í•˜ë©´ íšŒë³µ ê°€ëŠ¥!
   
[4ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰ (Alternative)]
   ì‹ í˜¸: "XX ì»¤ë®¤ë‹ˆí‹°ê°€ ë” ì¢‹ì•„ìš”", "ë‹¤ë¥¸ ê³³ ì•Œì•„ë´ì•¼ê² ì–´ìš”", ë¹„êµ ì–¸ê¸‰
   ì†Œì†ê°: ê±°ì˜ ì—†ìŒ | ìœ„í—˜ë„: 0.60-0.85
   
[5ë‹¨ê³„: ì‘ë³„ (Farewell)]
   ì‹ í˜¸: "ê·¸ë™ì•ˆ ê°ì‚¬í–ˆìŠµë‹ˆë‹¤", "ë§ˆì§€ë§‰ ê¸€", "íƒˆí‡´í•©ë‹ˆë‹¤", "ì•ˆë…•íˆ ê³„ì„¸ìš”"
   ì†Œì†ê°: ì—†ìŒ | ìœ„í—˜ë„: 0.85-1.0

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**2ì°¨ì› ë¶„ì„: ê°ì • Ã— ì†Œì†ê° (í•„ìˆ˜)**

**ê°ì • ì°¨ì›:**
- [ë§Œì¡±] ê¸ì •ì  í‘œí˜„, ê°ì‚¬
- [ë¬´ê´€ì‹¬] "ê·¸ëƒ¥", "ë³„ë¡œ ê´€ì‹¬", ë¬´ë°˜ì‘
- [ì§œì¦] "ì§œì¦ë‚˜ë„¤", ë¶ˆí‰, ë¹„ë‚œ
- [ì‹¤ë§] "ê¸°ëŒ€í–ˆëŠ”ë°", "ì•„ì‰½ë„¤ìš”", "ì‹¤ë§ì´ì—ìš”"
- [í¬ê¸°] "ì´ì œ ëì–´ìš”", "ê´€ë’€ì–´ìš”", "ì˜ë¯¸ì—†ì–´ìš”"

**ì†Œì†ê° ì§€í‘œ (í•µì‹¬!):**
ê°•í•¨: "ìš°ë¦¬", "ì—¬ê¸° ì‚¬ëŒë“¤", "ì¹œêµ¬ë“¤", "í•¨ê»˜", "ê°™ì´"
ë³´í†µ: "íšŒì›ë¶„ë“¤", "ì´ ì»¤ë®¤ë‹ˆí‹°", "ì—¬ëŸ¬ë¶„"
ì•½í•¨: "ë‚˜ë§Œ", "í˜¼ì", "ì™¸ë¡­ë„¤ìš”", "ì†Œí†µ ì•ˆë¼ìš”"
ì—†ìŒ: "ë‚¨", "ì§€ë‚˜ê°€ëŠ” ì‚¬ëŒ", "ë³„ë¡œ ê´€ì‹¬ ì—†ì–´ìš”"

**íŒì • ë§¤íŠ¸ë¦­ìŠ¤ (ëŒ€ìƒ ëª…ì‹œë¨):**
              ë§Œì¡±   ë¬´ê´€ì‹¬  ì§œì¦   ì‹¤ë§   í¬ê¸°
ê°•í•œ ì†Œì†ê°   0.1    0.2    0.4    0.5    0.7
ë³´í†µ ì†Œì†ê°   0.2    0.4    0.5    0.7    0.8
ì•½í•œ ì†Œì†ê°   0.4    0.5    0.7    0.8    0.9
ì—†ëŠ” ì†Œì†ê°   0.5    0.7    0.8    0.9    0.95

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ëŒ€ìƒ ëª…ì‹œ í™•ì¸ ê·œì¹™ (ìµœìš°ì„ ! ê³¼ëŒ€í‰ê°€ ë°©ì§€)**

ê°•í•œ ë¶€ì • í‚¤ì›Œë“œ("í¬ê¸°", "ë– ë‚˜ë‹¤", "ê·¸ë§Œë‘ë‹¤")ë„ ëŒ€ìƒì´ ëª…í™•í•´ì•¼ë§Œ ê³ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨í•œë‹¤.

[ëŒ€ìƒ ëª…ì‹œë¨ - ë†’ì€ ìœ„í—˜ë„ ìœ ì§€]
- "ì—¬ê¸° ë– ë‚ ë˜ìš”" â†’ 0.75-0.85
- "ì´ ì»¤ë®¤ë‹ˆí‹° ê·¸ë§Œë‘˜ê²Œìš”" â†’ 0.70-0.80
- "ì„œë¹„ìŠ¤ í¬ê¸°í•©ë‹ˆë‹¤" â†’ 0.65-0.75
- "íƒˆí‡´í• ê²Œìš”" â†’ 0.85-0.90 (ëª…ì‹œì  í–‰ë™ì–´)

[ëŒ€ìƒ ë¶ˆëª…í™• - ìœ„í—˜ë„ ëŒ€í­ í•˜í–¥ -0.35]
- "ëª¨ë“ ê±¸ í¬ê¸°í•˜ê³  ì‹¶ì–´ìš”" â†’ 0.30-0.40 (ì¼ë°˜ ê°ì •)
- "ë– ë‚˜ê³  ì‹¶ë„¤ìš”" â†’ 0.25-0.35 (ëŒ€ìƒ ì—†ìŒ)
- "ê·¸ë§Œë‘ê³  ì‹¶ì–´ìš”" â†’ 0.30-0.40 (ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±)
- "í˜ë“¤ì–´ìš”" â†’ 0.20-0.30 (ì‚¶ì˜ ê³ ë¯¼ ê°€ëŠ¥ì„±)

**íŒë‹¨ ê¸°ì¤€:**
1. "ì—¬ê¸°", "ì´ê³³", "ì„œë¹„ìŠ¤", "ì»¤ë®¤ë‹ˆí‹°", "ì‚¬ì´íŠ¸" ë“± **ëŒ€ìƒ ì§€ì‹œì–´ ìˆìŒ** â†’ ì›ë˜ ì ìˆ˜
2. ëŒ€ìƒ ì§€ì‹œì–´ **ì—†ê³ ** êµ¬ì²´ì  ë¶ˆë§Œë„ ì—†ìŒ â†’ **ì¼ë°˜ ê°ì •**ìœ¼ë¡œ ê°„ì£¼, ìœ„í—˜ë„ -0.35
3. "íƒˆí‡´", "ê³„ì • ì‚­ì œ" ê°™ì€ **ëª…ì‹œì  í–‰ë™ì–´** â†’ ëŒ€ìƒ ì—†ì–´ë„ ë†’ì€ ì ìˆ˜ ìœ ì§€ (ë‹¨, -0.15)

**ëŒ€ìƒ ë¶ˆëª…í™• ì‹œ ë³´ì •ëœ ë§¤íŠ¸ë¦­ìŠ¤:**
              ë§Œì¡±   ë¬´ê´€ì‹¬  ì§œì¦   ì‹¤ë§   í¬ê¸°
ì—†ëŠ” ì†Œì†ê°   0.15   0.35   0.45   0.55   0.60

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ì¡°ê±´ë¶€ í‘œí˜„ í•´ì„ ê°€ì´ë“œ (ë§¤ìš° ì¤‘ìš”!)**

**ì¡°ê±´ë¶€ ê¸ì • = í˜„ì¬ ë¶ˆë§Œì¡± ì‹ í˜¸!**
- "~í•˜ë©´/~ë˜ë©´ ê³„ì† ì“¸ê²Œìš”" â†’ í˜„ì¬ëŠ” ë¶ˆë§Œì¡± (ìœ„í—˜ë„ 0.4-0.6)
- "ê°œì„ ë˜ë©´ ë³¼ ì˜í–¥ ìˆìŠµë‹ˆë‹¤" â†’ ì§€ê¸ˆì€ ì•ˆ ë³´ê³  ìˆìŒ (ìœ„í—˜ë„ 0.45)
- "ì¢€ë§Œ ë” ì¢‹ìœ¼ë©´â€¦" â†’ ì‹¤ë§ê°ì˜ ì™„ê³¡ í‘œí˜„ (ìœ„í—˜ë„ 0.5)
- "ì¡°ê¸ˆë§Œ ë‚˜ì•„ì§€ë©´" â†’ í˜„ì¬ ìƒíƒœ ë¶ˆë§Œì¡± (ìœ„í—˜ë„ 0.4-0.5)

**ì™„ê³¡ í‘œí˜„ = ì‹¤ì œ ë¶ˆë§Œì˜ ì •ì¤‘í•œ í‘œí˜„!**
- "ì¢€â€¦", "ì¡°ê¸ˆâ€¦", "ì•½ê°„â€¦" â†’ ì‹¤ë§ê°ì„ ìˆ¨ê¸´ í‘œí˜„
- "â€¦" (ë§ì¤„ì„í‘œ) â†’ í•œìˆ¨, ì‹¤ë§, ì²´ë…
- "ê·¸ëƒ¥", "ë­" â†’ ë¬´ê´€ì‹¬ ë˜ëŠ” ì‹¤ë§

**ì¡°ê±´ë¶€ vs ë¬´ì¡°ê±´ë¶€ ë¹„êµ:**
[X] "ê°œì„ ë˜ë©´ ê³„ì† ë³¼ê²Œìš”" (0.45) = í˜„ì¬ ë¶ˆë§Œ + ì´íƒˆ ê³ ë ¤ ì¤‘
[O] "ê°œì„ ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤. ê³„ì† ë³¼ê²Œìš”" (0.2) = ê¸ì • + ë¯¸ë˜ ê¸°ëŒ€

**íŒë‹¨ ê·œì¹™:**
1. "~ë©´"ì´ í¬í•¨ë˜ë©´ â†’ ê·¸ê²ƒì´ ì¶©ì¡± ì•ˆ ëœ í˜„ì¬ ë¶ˆë§Œì¡± ì‹ í˜¸
2. ê°œì„  ìš”êµ¬ + ì¡°ê±´ë¶€ = 3ë‹¨ê³„(ê´€ê³„ ë‹¨ì ˆ) ì´ˆì… (0.4-0.5)
3. "ì˜í–¥ ìˆë‹¤"ëŠ” ê°€ëŠ¥ì„±ì¼ ë¿, í˜„ì¬ëŠ” ì•„ë‹˜ (ìœ„í—˜ë„ ê°ì†Œ NO)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ê¸´ê¸‰ì„± & íšŒë³µ ê°€ëŠ¥ì„± í‰ê°€**

**ê¸´ê¸‰ì„±:**
- IMMEDIATE (ì¦‰ì‹œ): "ì§€ê¸ˆ", "ì˜¤ëŠ˜", "ë‹¹ì¥" â†’ 24ì‹œê°„ ë‚´ ëŒ€ì‘
- SOON (ê³§): "ì´ë²ˆì£¼", "ë©°ì¹  ì•ˆì—" â†’ 1ì£¼ì¼ ë‚´ ëŒ€ì‘
- EVENTUAL (ì–¸ì  ê°€): "ìƒê°ì¤‘", "ê³ ë¯¼", "ë‚˜ì¤‘ì—" â†’ ëª¨ë‹ˆí„°ë§
- UNCLEAR (ë¶ˆëª…í™•): ì‹œê°„ ì–¸ê¸‰ ì—†ìŒ â†’ ì¶”ê°€ ê´€ì°°

**íšŒë³µ ê°€ëŠ¥ì„±:**
- HIGH: ì†Œì†ê° ë‚¨ì•„ìˆìŒ + êµ¬ì²´ì  ê°œì„  ìš”ì²­ + 3ë‹¨ê³„ ì´í•˜
- MEDIUM: ì†Œì†ê° ì•½í•¨ + ëŒ€ì•ˆ íƒìƒ‰ ì´ˆê¸° + 4ë‹¨ê³„
- LOW: ì†Œì†ê° ì—†ìŒ + ì´ë¯¸ ê²°ì • + 5ë‹¨ê³„

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ë¬¸ë§¥ ë¶„ì„ ì²´í¬ë¦¬ìŠ¤íŠ¸**

1. í†¤ ë¶„ì„:
   - ë†ë‹´/ì¥ë‚œ ("ã…‹ã…‹", "ã…ã…", "êµ¬ë¼", "ë°©êµ¬") â†’ ìœ„í—˜ë„ ë‚®ì¶¤
   - ì§„ì§€í•¨ (ë…¼ë¦¬ì , ì •ì¤‘í•¨, êµ¬ì²´ì  ë¶ˆë§Œ) â†’ ì›ë˜ í‰ê°€
   - ë¶„ë…¸/í¬ê¸° (ìš•ì„¤, ë‹¨ì •ì , "ì´ì œ ëì–´") â†’ ìœ„í—˜ë„ ë†’ì„

2. ì†Œì†ê° ë¶„ì„ (ê°€ì¥ ì¤‘ìš”!):
   - "ìš°ë¦¬", "í•¨ê»˜" ë“± í¬í•¨ì  ì–¸ì–´ ì‚¬ìš© ì—¬ë¶€
   - ì»¤ë®¤ë‹ˆí‹° ë©¤ë²„ì— ëŒ€í•œ ì–¸ê¸‰ (ê¸ì •/ë¶€ì •)
   - í˜¼ì/ì™¸ë¡­ë‹¤ëŠ” í‘œí˜„ ì—¬ë¶€

3. ì´íƒˆ ì˜ë„:
   - ëŒ€ì•ˆ ì»¤ë®¤ë‹ˆí‹°/ì„œë¹„ìŠ¤ ì–¸ê¸‰
   - ë¹„êµ í‘œí˜„ ("XXê°€ ë” ì¢‹ì•„ìš”")
   - ì‘ë³„ ì¸ì‚¬, ë§ˆì§€ë§‰ ê¸€ ì–¸ê¸‰

4. ì‹œê°„ ê¸´ê¸‰ì„±:
   - ì¦‰ì‹œì„± í‘œí˜„ ("ì§€ê¸ˆ", "ë‹¹ì¥")
   - ì´ë¯¸ ì‹¤í–‰ ì¤‘ ("ì•Œì•„ë³´ëŠ” ì¤‘", "ê°€ì…í–ˆì–´ìš”")

5. ëŒ€ìƒ ëª…ì‹œ (ì¤‘ìš”!):
   - "ì—¬ê¸°", "ì„œë¹„ìŠ¤", "ì»¤ë®¤ë‹ˆí‹°" ë“± ëª…ì‹œ â†’ ì›ë˜ ì ìˆ˜
   - ëŒ€ìƒ ì—†ëŠ” ê°ì • í‘œí˜„ â†’ ìœ„í—˜ë„ -0.35

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ì‹¤ì „ íŒì • ì˜ˆì‹œ**

[ì˜ˆì‹œ 1] "ê²€ìƒ‰ ì •í™•ë„ê°€ ì¢€ë§Œ ë” ì¢‹ìœ¼ë©´â€¦ ê´€ë ¨ ì—†ëŠ” ê¸€ì´ ìê¾¸ ì„ì—¬ìš”. ê°œì„ ë˜ë©´ ê³„ì† ë³¼ ì˜í–¥ ìˆìŠµë‹ˆë‹¤"
â†’ 3ë‹¨ê³„(ê´€ê³„ ë‹¨ì ˆ) ì´ˆì…, ì‹¤ë§, ë³´í†µ~ì•½í•œ ì†Œì†ê°, 0.45, MEDIUM
â†’ ì´ìœ : "ì¢€ë§Œ ë”" + "â€¦" = ì‹¤ë§ ì™„ê³¡ í‘œí˜„, "ê°œì„ ë˜ë©´"= ì¡°ê±´ë¶€(í˜„ì¬ ë¶ˆë§Œì¡±), "ìê¾¸" = ë°˜ë³µì  ë¶ˆë§Œ
â†’ ì•¡ì…˜: ì¦‰ì‹œ ê°œì„  í”¼ë“œë°± ìˆ˜ì§‘, ê¸ì • ê²½í—˜ ì œê³µ, ê³¨ë“  íƒ€ì„ ê°œì…

[ì˜ˆì‹œ 2] "ìš”ì¦˜ ì—¬ê¸° ë³„ë¡œë„¤ìš”. ì‚¬ëŒë“¤ì´ ì˜ˆì „ê°™ì§€ ì•Šì•„ìš”"
â†’ 3ë‹¨ê³„(ê´€ê³„ ë‹¨ì ˆ), ì‹¤ë§, ì•½í•œ ì†Œì†ê°, 0.55, HIGH, íšŒë³µê°€ëŠ¥ì„± ë†’ìŒ
â†’ ì•¡ì…˜: ì¦‰ì‹œ ê°œì… - 3ë‹¨ê³„ëŠ” ê³¨ë“  íƒ€ì„!

[ì˜ˆì‹œ 3] "XX ì»¤ë®¤ë‹ˆí‹°ê°€ ë” í™œë°œí•˜ë˜ë°ìš”. ê±°ê¸°ë„ ê°€ë´ì•¼ê² ì–´ìš”"
â†’ 4ë‹¨ê³„(ëŒ€ì•ˆ íƒìƒ‰), ë¬´ê´€ì‹¬, ê±°ì˜ ì—†ëŠ” ì†Œì†ê°, 0.78, CRITICAL, íšŒë³µê°€ëŠ¥ì„± ì¤‘ê°„
â†’ ì•¡ì…˜: 24ì‹œê°„ ë‚´ ê¸´ê¸‰ ëŒ€ì‘

[ì˜ˆì‹œ 4] "íƒˆí‡´í• ê¹Œ ã…‹ã…‹ ê·¼ë° ì¹œêµ¬ë“¤ì´ ì—¬ê¸° ìˆì–´ì„œ..."
â†’ 2ë‹¨ê³„(ì†Œê·¹ ì°¸ì—¬), ë¬´ê´€ì‹¬, ë³´í†µ ì†Œì†ê°(ì¹œêµ¬), 0.35, MEDIUM, íšŒë³µê°€ëŠ¥ì„± ë†’ìŒ
â†’ ì•¡ì…˜: ì¹œêµ¬ ë„¤íŠ¸ì›Œí¬ í™œì„±í™”, ëª¨ë‹ˆí„°ë§

[ì˜ˆì‹œ 5] "íƒˆí‡´í• ê±°ì„ ã…‹ã…‹ ë°©êµ¬ë‚˜ ë¨¹ì–´ë¼ ë¿¡"
â†’ 1ë‹¨ê³„(í™œë°œ), ë†ë‹´ í†¤, ì†Œì†ê° ìœ ì§€, 0.12, LOW
â†’ ì•¡ì…˜: ì •ìƒì  í™œë™, ê´€ì°°ë§Œ

[ì˜ˆì‹œ 6] "ëª¨ë“ ê±¸ í¬ê¸°í•˜ê³  ë– ë‚˜ê³  ì‹¶ë„¤ìš”"
â†’ 2ë‹¨ê³„(ì†Œê·¹ ì°¸ì—¬), í¬ê¸° ê°ì •, ëŒ€ìƒ ë¶ˆëª…í™•, 0.35, MEDIUM
â†’ ì´ìœ : ëŒ€ìƒ ì§€ì‹œì–´ ì—†ìŒ, ì¼ë°˜ì  ê°ì • í‘œí˜„ ê°€ëŠ¥ì„±, ì„œë¹„ìŠ¤ì™€ì˜ ì—°ê´€ì„± ë¶ˆëª…í™•
â†’ ì•¡ì…˜: ëª¨ë‹ˆí„°ë§, ë‹¤ìŒ ê²Œì‹œê¸€ì—ì„œ ì»¨í…ìŠ¤íŠ¸ í™•ì¸

[ì˜ˆì‹œ 7] "ì—¬ê¸° ëª¨ë“ ê²Œ ë³„ë¡œë„¤ìš”. í¬ê¸°í•˜ê³  ë– ë‚ ë˜ìš”"
â†’ 4ë‹¨ê³„(ëŒ€ì•ˆ íƒìƒ‰), í¬ê¸° ê°ì •, ì•½í•œ ì†Œì†ê°, 0.85, CRITICAL
â†’ ì´ìœ : ëŒ€ìƒ ëª…ì‹œ + ê°•í•œ ë¶€ì • + í™•ì •ì  ì˜ë„
â†’ ì•¡ì…˜: 24ì‹œê°„ ë‚´ ê¸´ê¸‰ ê°œì…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**JSON ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (í•„ìˆ˜)**

{
  "risk_score": 0.0~1.0,
  "priority": "LOW"|"MEDIUM"|"HIGH"|"CRITICAL",
  "churn_stage": "1ë‹¨ê³„: í™œë°œ ì°¸ì—¬"|"2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬"|"3ë‹¨ê³„: ê´€ê³„ ë‹¨ì ˆ"|"4ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰"|"5ë‹¨ê³„: ì‘ë³„",
  "belongingness": "ê°•í•¨"|"ë³´í†µ"|"ì•½í•¨"|"ì—†ìŒ",
  "emotion": "ë§Œì¡±"|"ë¬´ê´€ì‹¬"|"ì§œì¦"|"ì‹¤ë§"|"í¬ê¸°",
  "urgency": "IMMEDIATE"|"SOON"|"EVENTUAL"|"UNCLEAR",
  "recovery_chance": "HIGH"|"MEDIUM"|"LOW",
  "reasons": [ë¬¸ìì—´ 2~5ê°œ - íŒë‹¨ ê·¼ê±°, ì†Œì†ê° ë¶„ì„ í•„ìˆ˜ í¬í•¨],
  "actions": [ë¬¸ìì—´ 2~5ê°œ - êµ¬ì²´ì  ëŒ€ì‘ ë°©ì•ˆ, ë‹¨ê³„ë³„ ë§ì¶¤ ì œì•ˆ],
  "evidence_ids": [ì°¸ê³ í•œ evidence IDë“¤ì˜ ì• 8ìë¦¬]
}

**ì•¡ì…˜ ìœ í˜• ê°€ì´ë“œ:**
- 1-2ë‹¨ê³„: ì˜ˆë°©ì  ì°¸ì—¬ ìœ ë„, ê¸ì • ê²½í—˜ ê°•í™”
- 3ë‹¨ê³„: ì¦‰ì‹œ ê°œì…, ê´€ê³„ íšŒë³µ, ì†Œì†ê° ê°•í™” (ê³¨ë“  íƒ€ì„!)
- 4ë‹¨ê³„: ê¸´ê¸‰ ëŒ€ì‘, ìš°ë¦¬ë§Œì˜ ê°€ì¹˜ ì–´í•„, íŠ¹ë³„ í˜œíƒ
- 5ë‹¨ê³„: ìµœì†Œí•œì˜ ì‹œë„, ì¬ê°€ì… ìœ ë„ ì¥ì¹˜ ë§ˆë ¨"""


def _create_user_prompt(context: Dict[str, Any]) -> str:
    """
    ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        context (Dict[str, Any]): ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        str: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
    """
    post_info = context.get("post", {})
    evidence_list = context.get("evidence", [])
    stats = context.get("stats", {})
    
    # í˜„ì¬ ê¸€ ê°œìš”
    post_section = f"""[í˜„ì¬ ê¸€ ê°œìš”]
- user_id: {post_info.get('user_id', 'N/A')}
- post_id: {post_info.get('post_id', 'N/A')}
- created_at: {post_info.get('created_at', 'N/A')}
- ì›ë¬¸: "{post_info.get('original_text', '')[:200]}{'...' if len(post_info.get('original_text', '')) > 200 else ''}"

[ë¶„ì„ í†µê³„]
- ì „ì²´ ë¬¸ì¥ ìˆ˜: {stats.get('total_sentences', 0)}
- ë§¤ì¹­ëœ ìœ„í—˜ ë¬¸ì¥ ìˆ˜: {stats.get('total_matches', 0)}
- ìµœê³  ìœ ì‚¬ë„: {stats.get('max_score', 0.0):.3f}
- í‰ê·  ìœ ì‚¬ë„: {stats.get('avg_score', 0.0):.3f}
- ê³ ìœ„í—˜ ë¬¸ì¥ í¬í•¨: {'ì˜ˆ' if stats.get('has_high_risk', False) else 'ì•„ë‹ˆì˜¤'}"""
    
    # ì¦ê±° ë¬¸ì¥ ëª¨ìŒ
    evidence_section = "[ì¦ê±° ë¬¸ì¥ ëª¨ìŒ (í™•ì¸ëœ ìœ„í—˜ ë¬¸ì¥, ìœ ì‚¬ë„ ë†’ì€ ìˆœ)]"
    
    if evidence_list:
        for i, evidence in enumerate(evidence_list[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            evidence_section += f"""
{i}. ID: {evidence.get('vector_chunk_id', 'N/A')[:8]}...
   - ì›ë³¸ ë¬¸ì¥: "{evidence.get('sentence', '')}"
   - ë§¤ì¹­ëœ ìœ„í—˜ ë¬¸ì¥: "{evidence.get('matched_sentence', '')}"
   - ìœ ì‚¬ë„: {evidence.get('matched_score', 0.0):.3f}
   - ì›ë˜ ìœ„í—˜ì ìˆ˜: {evidence.get('risk_score', 0.0):.3f}
   - ë§¤ì¹­ ê²Œì‹œë¬¼: {evidence.get('matched_post_id', 'N/A')}
   - ë§¤ì¹­ ì‹œì : {evidence.get('matched_created_at', 'N/A')}"""
    else:
        evidence_section += "\n(ë§¤ì¹­ëœ ìœ„í—˜ ë¬¸ì¥ ì—†ìŒ)"
    
    # ìš”êµ¬ì‚¬í•­ (ì»¤ë®¤ë‹ˆí‹° íŠ¹í™” ìŠ¤í‚¤ë§ˆ)
    requirement_section = """
[ìš”êµ¬ì‚¬í•­]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ë‹µí•˜ë¼. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.

{
  "risk_score": 0.0~1.0 ìˆ«ì,
  "priority": "LOW"|"MEDIUM"|"HIGH"|"CRITICAL",
  "churn_stage": "1ë‹¨ê³„: í™œë°œ ì°¸ì—¬"|"2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬"|"3ë‹¨ê³„: ê´€ê³„ ë‹¨ì ˆ"|"4ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰"|"5ë‹¨ê³„: ì‘ë³„",
  "belongingness": "ê°•í•¨"|"ë³´í†µ"|"ì•½í•¨"|"ì—†ìŒ",
  "emotion": "ë§Œì¡±"|"ë¬´ê´€ì‹¬"|"ì§œì¦"|"ì‹¤ë§"|"í¬ê¸°",
  "urgency": "IMMEDIATE"|"SOON"|"EVENTUAL"|"UNCLEAR",
  "recovery_chance": "HIGH"|"MEDIUM"|"LOW",
  "reasons": [ë¬¸ìì—´ 2~5ê°œ - íŒë‹¨ ê·¼ê±°, ì†Œì†ê° ë¶„ì„ í•„ìˆ˜ í¬í•¨],
  "actions": [ë¬¸ìì—´ 2~5ê°œ - êµ¬ì²´ì  ëŒ€ì‘ ë°©ì•ˆ, ë‹¨ê³„ë³„ ë§ì¶¤ ì œì•ˆ],
  "evidence_ids": [ì°¸ê³ í•œ evidence IDë“¤ì˜ ì• 8ìë¦¬]
}"""
    
    return f"{post_section}\n\n{evidence_section}\n{requirement_section}"


def _parse_llm_response(response_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
    """
    LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        response_text (str): LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        context (Dict[str, Any]): ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ (fallbackìš©)
        
    Returns:
        Dict[str, Any]: íŒŒì‹±ëœ ê²°ì • ê²°ê³¼
    """
    try:
        # ğŸ” ë””ë²„ê·¸: LLM ì›ë³¸ ì‘ë‹µ ì¶œë ¥
        logger.info(f"[DEBUG] LLM ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 500ì): {response_text[:500]}")
        
        # JSON íŒŒì‹± ì‹œë„
        decision = json.loads(response_text)
        
        # ğŸ” ë””ë²„ê·¸: íŒŒì‹±ëœ JSON ì¶œë ¥
        logger.info(f"[DEBUG] íŒŒì‹±ëœ JSON í‚¤: {list(decision.keys())}")
        logger.info(f"[DEBUG] risk_score: {decision.get('risk_score')}, priority: {decision.get('priority')}")
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì • (ì»¤ë®¤ë‹ˆí‹° íŠ¹í™” í•„ë“œ í¬í•¨)
        validated_decision = {
            "risk_score": _validate_risk_score(decision.get("risk_score")),
            "priority": _validate_priority(decision.get("priority")),
            "churn_stage": _validate_churn_stage(decision.get("churn_stage")),
            "belongingness": _validate_belongingness(decision.get("belongingness")),
            "emotion": _validate_emotion(decision.get("emotion")),
            "urgency": _validate_urgency(decision.get("urgency")),
            "recovery_chance": _validate_recovery_chance(decision.get("recovery_chance")),
            "reasons": _validate_string_list(decision.get("reasons"), 2, 5, "íŒë‹¨ ê·¼ê±°"),
            "actions": _validate_string_list(decision.get("actions"), 2, 5, "ëŒ€ì‘ ë°©ì•ˆ"),
            "evidence_ids": _validate_evidence_ids(decision.get("evidence_ids"), context)
        }
        
        logger.info(f"[DEBUG] ê²€ì¦ í›„ risk_score: {validated_decision['risk_score']}, reasons: {validated_decision['reasons'][:2]}")
        logger.debug("LLM ì‘ë‹µ íŒŒì‹± ë° ê²€ì¦ ì™„ë£Œ (ì»¤ë®¤ë‹ˆí‹° íŠ¹í™”)")
        return validated_decision
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        logger.error(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì‘ë‹µ ì „ì²´: {response_text}")
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return _get_fallback_decision(context, error="JSON íŒŒì‹± ì‹¤íŒ¨")
        
    except Exception as e:
        logger.error(f"ì‘ë‹µ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‘ë‹µ: {response_text[:200]}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return _get_fallback_decision(context, error="ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨")


def _validate_risk_score(score: Any) -> float:
    """ìœ„í—˜ ì ìˆ˜ë¥¼ ê²€ì¦í•˜ê³  0.0~1.0 ë²”ìœ„ë¡œ ì œí•œí•©ë‹ˆë‹¤."""
    try:
        score = float(score)
        return max(0.0, min(1.0, score))
    except (TypeError, ValueError):
        return 0.5  # ê¸°ë³¸ê°’


def _validate_priority(priority: Any) -> str:
    """ìš°ì„ ìˆœìœ„ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    if priority in ["LOW", "MEDIUM", "HIGH", "CRITICAL"]:
        return priority
    return "MEDIUM"  # ê¸°ë³¸ê°’


def _validate_churn_stage(stage: Any) -> str:
    """ì´íƒˆ ë‹¨ê³„ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    valid_stages = [
        "1ë‹¨ê³„: í™œë°œ ì°¸ì—¬",
        "2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬",
        "3ë‹¨ê³„: ê´€ê³„ ë‹¨ì ˆ",
        "4ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰",
        "5ë‹¨ê³„: ì‘ë³„"
    ]
    if stage in valid_stages:
        return stage
    return "2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬"  # ê¸°ë³¸ê°’


def _validate_belongingness(belongingness: Any) -> str:
    """ì†Œì†ê°ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    if belongingness in ["ê°•í•¨", "ë³´í†µ", "ì•½í•¨", "ì—†ìŒ"]:
        return belongingness
    return "ë³´í†µ"  # ê¸°ë³¸ê°’


def _validate_emotion(emotion: Any) -> str:
    """ê°ì •ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    if emotion in ["ë§Œì¡±", "ë¬´ê´€ì‹¬", "ì§œì¦", "ì‹¤ë§", "í¬ê¸°"]:
        return emotion
    return "ë¬´ê´€ì‹¬"  # ê¸°ë³¸ê°’


def _validate_urgency(urgency: Any) -> str:
    """ê¸´ê¸‰ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    if urgency in ["IMMEDIATE", "SOON", "EVENTUAL", "UNCLEAR"]:
        return urgency
    return "UNCLEAR"  # ê¸°ë³¸ê°’


def _validate_recovery_chance(chance: Any) -> str:
    """íšŒë³µ ê°€ëŠ¥ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    if chance in ["HIGH", "MEDIUM", "LOW"]:
        return chance
    return "MEDIUM"  # ê¸°ë³¸ê°’


def _validate_string_list(items: Any, min_count: int, max_count: int, default_prefix: str) -> List[str]:
    """ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not isinstance(items, list):
        return [f"{default_prefix} ë¶„ì„ í•„ìš”"] * min_count
    
    # ë¬¸ìì—´ë§Œ í•„í„°ë§
    valid_items = [str(item) for item in items if item and str(item).strip()]
    
    # ê°œìˆ˜ ì¡°ì •
    if len(valid_items) < min_count:
        while len(valid_items) < min_count:
            valid_items.append(f"{default_prefix} ì¶”ê°€ ë¶„ì„ í•„ìš”")
    elif len(valid_items) > max_count:
        valid_items = valid_items[:max_count]
    
    return valid_items


def _validate_evidence_ids(ids: Any, context: Dict[str, Any]) -> List[str]:
    """ì¦ê±° ID ë¦¬ìŠ¤íŠ¸ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not isinstance(ids, list):
        ids = []
    
    # ìœ íš¨í•œ ì¦ê±° IDë“¤ ì¶”ì¶œ
    evidence_list = context.get("evidence", [])
    available_ids = [e.get("vector_chunk_id", "")[:8] for e in evidence_list if e.get("vector_chunk_id")]
    
    # ì…ë ¥ëœ IDë“¤ ì¤‘ ìœ íš¨í•œ ê²ƒë§Œ í•„í„°ë§
    valid_ids = []
    for id_item in ids:
        id_str = str(id_item)[:8] if id_item else ""
        if id_str in available_ids:
            valid_ids.append(id_str)
    
    return valid_ids


def _get_fallback_decision(context: Dict[str, Any], error: Optional[str] = None) -> Dict[str, Any]:
    """
    LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ê²°ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        context (Dict[str, Any]): ì›ë³¸ ì»¨í…ìŠ¤íŠ¸
        error (str, optional): ì˜¤ë¥˜ ë©”ì‹œì§€
        
    Returns:
        Dict[str, Any]: ê¸°ë³¸ ê²°ì •
    """
    stats = context.get("stats", {})
    evidence_list = context.get("evidence", [])
    
    # í†µê³„ ê¸°ë°˜ ê°„ë‹¨í•œ ìœ„í—˜ë„ ê³„ì‚°
    max_score = stats.get("max_score", 0.0)
    total_matches = stats.get("total_matches", 0)
    has_high_risk = stats.get("has_high_risk", False)
    
    # ìœ„í—˜ë„ ì ìˆ˜ ê²°ì •
    if has_high_risk and max_score >= 0.8:
        risk_score = 0.8
        priority = "HIGH"
    elif total_matches >= 2 and max_score >= 0.5:
        risk_score = 0.6
        priority = "MEDIUM"
    elif total_matches >= 1:
        risk_score = 0.4
        priority = "MEDIUM"
    else:
        risk_score = 0.2
        priority = "LOW"
    
    # ê¸°ë³¸ ì´ìœ ì™€ ì•¡ì…˜
    reasons = [
        f"ìœ ì‚¬í•œ ìœ„í—˜ ë¬¸ì¥ {total_matches}ê°œ ë°œê²¬",
        f"ìµœê³  ìœ ì‚¬ë„ {max_score:.3f}",
    ]
    
    if has_high_risk:
        reasons.append("ê³ ìœ„í—˜ íŒ¨í„´ ê°ì§€ë¨")
    
    actions = [
        "ì‚¬ìš©ì í™œë™ ëª¨ë‹ˆí„°ë§ ê°•í™”",
        "ê³ ê° ë§Œì¡±ë„ ì¡°ì‚¬ ì‹¤ì‹œ"
    ]
    
    if priority == "HIGH":
        actions.append("ì¦‰ì‹œ ê³ ê° ì§€ì›íŒ€ ì—°ë½")
    elif priority == "MEDIUM":
        actions.append("ì˜ˆë°©ì  ì†Œí†µ í”„ë¡œê·¸ë¨ ì ìš©")
    
    # ì¦ê±° ID ìˆ˜ì§‘
    evidence_ids = [e.get("vector_chunk_id", "")[:8] for e in evidence_list[:3] if e.get("vector_chunk_id")]
    
    # ì»¤ë®¤ë‹ˆí‹° íŠ¹í™” í•„ë“œ ì¶”ë¡ 
    if risk_score >= 0.85:
        churn_stage = "5ë‹¨ê³„: ì‘ë³„"
        belongingness = "ì—†ìŒ"
        emotion = "í¬ê¸°"
        urgency = "IMMEDIATE"
        recovery_chance = "LOW"
    elif risk_score >= 0.6:
        churn_stage = "4ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰"
        belongingness = "ì•½í•¨"
        emotion = "ì‹¤ë§"
        urgency = "SOON"
        recovery_chance = "MEDIUM"
    elif risk_score >= 0.35:
        churn_stage = "3ë‹¨ê³„: ê´€ê³„ ë‹¨ì ˆ"
        belongingness = "ë³´í†µ"
        emotion = "ë¬´ê´€ì‹¬"
        urgency = "EVENTUAL"
        recovery_chance = "HIGH"
    elif risk_score >= 0.15:
        churn_stage = "2ë‹¨ê³„: ì†Œê·¹ ì°¸ì—¬"
        belongingness = "ë³´í†µ"
        emotion = "ë¬´ê´€ì‹¬"
        urgency = "UNCLEAR"
        recovery_chance = "HIGH"
    else:
        churn_stage = "1ë‹¨ê³„: í™œë°œ ì°¸ì—¬"
        belongingness = "ê°•í•¨"
        emotion = "ë§Œì¡±"
        urgency = "UNCLEAR"
        recovery_chance = "HIGH"
    
    fallback = {
        "risk_score": risk_score,
        "priority": priority,
        "churn_stage": churn_stage,
        "belongingness": belongingness,
        "emotion": emotion,
        "urgency": urgency,
        "recovery_chance": recovery_chance,
        "reasons": reasons[:5],  # ìµœëŒ€ 5ê°œ
        "actions": actions[:5],  # ìµœëŒ€ 5ê°œ
        "evidence_ids": evidence_ids,
        "confidence": "Low" if evidence_list else "Uncertain"
    }
    
    if error:
        fallback["fallback_reason"] = error
        logger.warning(f"ê¸°ë³¸ê°’ ì‚¬ìš© (ì»¤ë®¤ë‹ˆí‹° íŠ¹í™”): {error}")
    
    return fallback


def _finalize_decision(decision: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """
    ìµœì¢… ì‘ë‹µ êµ¬ì¡°ë¥¼ ì •ë¦¬í•˜ê³  report_schema í˜•íƒœë¥¼ í¬í•¨ì‹œí‚µë‹ˆë‹¤.
    """
    stats = context.get("stats", {})
    evidence = context.get("evidence", [])
    decision = dict(decision)
    
    decision.setdefault("priority", "LOW")
    decision.setdefault("risk_score", 0.0)
    decision.setdefault("reasons", [])
    decision.setdefault("actions", [])
    decision.setdefault("evidence_ids", [])
    
    decision["reason"] = _build_reason_summary(decision, stats, evidence)
    
    report, report_validation = _build_report_payload(decision, context)
    decision["report"] = report
    decision["report_valid"] = report_validation[0]
    if report_validation[1]:
        decision["report_error"] = report_validation[1]
    
    return decision


def _build_reason_summary(decision: Dict[str, Any], stats: Dict[str, Any], evidence: List[Dict[str, Any]]) -> str:
    total_matches = stats.get("total_matches", len(evidence))
    max_score = stats.get("max_score")
    if max_score is None and evidence:
        max_score = max((float(ev.get("matched_score") or ev.get("similarity_score") or 0.0) for ev in evidence), default=0.0)
    max_score = float(max_score or 0.0)
    
    priority = decision.get("priority", "LOW")
    reasons = decision.get("reasons") or []
    primary_reason = reasons[0] if reasons else "ì¶”ê°€ ê·¼ê±° ë¶„ì„ í•„ìš”"
    
    line1 = f"{priority} ìœ„í—˜ë„ë¡œ íŒì •í–ˆìŠµë‹ˆë‹¤. ê·¼ê±° {total_matches}ê±´, ìµœê³  ìœ ì‚¬ë„ {max_score * 100:.1f}%."
    line2 = f"í•µì‹¬ ê·¼ê±°: {primary_reason}"
    return f"{line1} {line2}".strip()


def _build_report_payload(decision: Dict[str, Any], context: Dict[str, Any]) -> Tuple[Dict[str, Any], Tuple[bool, Optional[str]]]:
    evidence_rows = _convert_evidence_for_report(context.get("evidence", []), decision.get("evidence_ids", []))
    warnings = []
    fallback_reason = decision.get("fallback_reason")
    if fallback_reason:
        warnings.append(f"fallback:{fallback_reason}")
    
    report = create_report_schema(
        summary=decision.get("reason", ""),
        risk_level=(decision.get("priority") or "LOW").lower(),
        evidence=evidence_rows,
        actions=decision.get("actions", []),
        model=decision.get("model", LLM_MODEL if decision.get("confidence") != "Uncertain" else REPORT_DEFAULT_MODEL),
        prompt_v=f"{REPORT_PROMPT_VERSION}-rag-decider",
        warnings=warnings or None
    )
    
    is_valid, error = validate_report_schema(report)
    if not is_valid:
        logger.error("[RAG] report_schema ê²€ì¦ ì‹¤íŒ¨: %s", error)
    
    return report, (is_valid, error)


def _convert_evidence_for_report(evidence_list: List[Dict[str, Any]], evidence_ids: List[str]) -> List[Dict[str, Any]]:
    converted = []
    for idx, item in enumerate(evidence_list):
        chunk_id = (
            item.get("vector_chunk_id")
            or item.get("chunk_id")
            or item.get("id")
            or (evidence_ids[idx] if idx < len(evidence_ids) else f"ev_{idx}")
        )
        sentence = item.get("matched_sentence") or item.get("sentence") or ""
        similarity = (
            item.get("matched_score")
            or item.get("similarity_score")
            or item.get("score")
            or 0.0
        )
        
        converted.append({
            "id": str(chunk_id)[:16],
            "snippet": sentence[:200],
            "similarity": round(float(similarity), 3)
        })
    return converted


def _is_timeout_error(error: Exception) -> bool:
    timeout_indicators = ("timeout", "timed out")
    message = str(error).lower()
    if any(indicator in message for indicator in timeout_indicators):
        return True
    
    if isinstance(error, TimeoutError):
        return True
    
    # OpenAI ì „ìš© íƒ€ì„ì•„ì›ƒ ì˜ˆì™¸ í™•ì¸
    try:
        from openai import error as openai_errors  # type: ignore
        timeout_cls = getattr(openai_errors, "Timeout", None)
        if timeout_cls and isinstance(error, timeout_cls):
            return True
        api_timeout_cls = getattr(openai_errors, "APITimeoutError", None)
        if api_timeout_cls and isinstance(error, api_timeout_cls):
            return True
    except ImportError:
        pass
    
    return False


# í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…ìš© í•¨ìˆ˜ë“¤
def test_llm_connection() -> Dict[str, Any]:
    """
    LLM ì—°ê²° ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: í…ŒìŠ¤íŠ¸ ê²°ê³¼
    """
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        return {
            "status": "error",
            "message": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key, timeout=10)
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=10
        )
        
        return {
            "status": "success",
            "message": "LLM ì—°ê²° ì„±ê³µ",
            "model": LLM_MODEL,
            "response_length": len(response.choices[0].message.content)
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": f"LLM ì—°ê²° ì‹¤íŒ¨: {str(e)}"
        }


def create_test_context() -> Dict[str, Any]:
    """
    í…ŒìŠ¤íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, Any]: í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
    """
    return {
        "post": {
            "user_id": "test_user_123",
            "post_id": "test_post_456",
            "created_at": "2024-11-04T15:30:00",
            "original_text": "ì´ ì„œë¹„ìŠ¤ ì •ë§ ë³„ë¡œë„¤ìš”. ë” ì´ìƒ ì‚¬ìš©í•˜ê³  ì‹¶ì§€ ì•Šì•„ìš”."
        },
        "evidence": [
            {
                "sentence": "ë” ì´ìƒ ì‚¬ìš©í•˜ê³  ì‹¶ì§€ ì•Šì•„ìš”.",
                "risk_score": 0.87,
                "matched_score": 0.92,
                "matched_sentence": "íƒˆí‡´í• ê¹Œ ìƒê°ì¤‘ì…ë‹ˆë‹¤",
                "matched_post_id": "post_456",
                "matched_created_at": "2025-10-31T13:45:00",
                "vector_chunk_id": "abc12345def67890"
            }
        ],
        "stats": {
            "total_sentences": 2,
            "total_matches": 1,
            "max_score": 0.92,
            "avg_score": 0.92,
            "has_high_risk": True
        }
    }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("RAG ê²°ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # LLM ì—°ê²° í…ŒìŠ¤íŠ¸
    connection_test = test_llm_connection()
    print(f"LLM ì—°ê²° í…ŒìŠ¤íŠ¸: {connection_test}")
    
    # í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°ì • í…ŒìŠ¤íŠ¸
    if connection_test["status"] == "success":
        test_context = create_test_context()
        decision = decide_with_rag(test_context)
        print(f"í…ŒìŠ¤íŠ¸ ê²°ì • ê²°ê³¼: {json.dumps(decision, ensure_ascii=False, indent=2)}")
    
    print("RAG ê²°ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
