"""
Agent ë„êµ¬ ì •ì˜
5ê°œ ì¡°íšŒ ë„êµ¬ + 2ê°œ ì‹¤í–‰ ë„êµ¬
ì¡°íšŒ: semantic_search, churn_analysis, ethics_check, match_reports, trends_analysis
ì‹¤í–‰: execute_churn_analysis, execute_ethics_analysis
"""

import json
import os
from pathlib import Path
from typing import Dict, List
from datetime import datetime, timedelta
from langchain_core.tools import tool
from langchain_community.vectorstores import Chroma
# EnsembleRetrieverëŠ” ì§ì ‘ êµ¬í˜„
from agent_back.bm25_store import BM25Store

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent

# ChromaDB ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ chroma_store ì‚¬ìš©)
CHROMA_DB_PATH = PROJECT_ROOT / "chroma_store"

# ì„ë² ë”© ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
_embeddings = None
_vectorstore = None
_bm25_store = None
_ensemble_retriever = None

# ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ (ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸°ì—ì„œ ì‚¬ìš©)
_last_search_board_ids = []


def get_embeddings():
    """BGE-M3 ì„ë² ë”© ëª¨ë¸ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _embeddings
    if _embeddings is None:
        from agent_back.bge_m3_embeddings import BGEM3Embeddings
        _embeddings = BGEM3Embeddings()
    return _embeddings


def get_vectorstore():
    """ChromaDB vectorstore ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _vectorstore
    if _vectorstore is None:
        embeddings = get_embeddings()
        _vectorstore = Chroma(
            persist_directory=str(CHROMA_DB_PATH),
            embedding_function=embeddings,
            collection_name="board_comments"
        )
    return _vectorstore


def get_bm25_store():
    """BM25Store ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _bm25_store
    if _bm25_store is None:
        bm25_path = CHROMA_DB_PATH / "bm25_index.pkl"
        if bm25_path.exists():
            _bm25_store = BM25Store.load_index(str(bm25_path))
        else:
            raise FileNotFoundError(
                f"BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {bm25_path}\n"
                "ë¨¼ì € 'python embed_board_comments.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”."
            )
    return _bm25_store


def get_ensemble_retriever():
    """EnsembleRetriever ë°˜í™˜ (BM25 + Vector ê²°í•©)"""
    global _ensemble_retriever
    if _ensemble_retriever is None:
        try:
            # Vector ê²€ìƒ‰ê¸°ì™€ BM25 ê²€ìƒ‰ê¸°ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸°
            _ensemble_retriever = CustomEnsembleRetriever()
            print("[OK] CustomEnsembleRetriever ì´ˆê¸°í™” ì™„ë£Œ (BM25 + Vector)")
            
        except Exception as e:
            print(f"[WARN] EnsembleRetriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("[INFO] Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # ì‹¤íŒ¨ ì‹œ Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©
            vectorstore = get_vectorstore()
            _ensemble_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    
    return _ensemble_retriever


class CustomEnsembleRetriever:
    """
    BM25ì™€ Vector ê²€ìƒ‰ì„ ê²°í•©í•˜ëŠ” ì»¤ìŠ¤í…€ ì•™ìƒë¸” ê²€ìƒ‰ê¸°
    """
    
    def __init__(self, bm25_weight: float = 0.5, vector_weight: float = 0.5):
        """
        Args:
            bm25_weight: BM25 ê²€ìƒ‰ ê²°ê³¼ ê°€ì¤‘ì¹˜
            vector_weight: Vector ê²€ìƒ‰ ê²°ê³¼ ê°€ì¤‘ì¹˜
        """
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
    
    def get_relevant_documents(self, query: str, k: int = 10):
        """
        ì•™ìƒë¸” ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            ê´€ë ¨ Document ë¦¬ìŠ¤íŠ¸
        """
        try:
            # BM25 ê²€ìƒ‰
            bm25_store = get_bm25_store()
            bm25_results = bm25_store.search(query, k=k*2)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ë‹¤ì–‘ì„± í™•ë³´
            
            # Vector ê²€ìƒ‰
            vectorstore = get_vectorstore()
            vector_results = vectorstore.similarity_search_with_score(query, k=k*2)
            
            # ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            combined_docs = {}
            
            # BM25 ê²°ê³¼ ì¶”ê°€
            for doc, score in bm25_results:
                doc_id = self._get_doc_id(doc)
                if doc_id not in combined_docs:
                    combined_docs[doc_id] = {
                        'doc': doc,
                        'bm25_score': score * self.bm25_weight,
                        'vector_score': 0.0
                    }
            
            # Vector ê²°ê³¼ ì¶”ê°€ (ì ìˆ˜ ì •ê·œí™”)
            for doc, distance in vector_results:
                doc_id = self._get_doc_id(doc)
                # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ ë†’ìŒ)
                similarity = max(0, 1.0 - distance)
                
                if doc_id in combined_docs:
                    combined_docs[doc_id]['vector_score'] = similarity * self.vector_weight
                else:
                    combined_docs[doc_id] = {
                        'doc': doc,
                        'bm25_score': 0.0,
                        'vector_score': similarity * self.vector_weight
                    }
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            final_results = []
            for doc_info in combined_docs.values():
                final_score = doc_info['bm25_score'] + doc_info['vector_score']
                final_results.append((doc_info['doc'], final_score))
            
            # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            final_results.sort(key=lambda x: x[1], reverse=True)
            
            # ìƒìœ„ kê°œ ë°˜í™˜
            return [doc for doc, score in final_results[:k]]
            
        except Exception as e:
            print(f"[WARN] ì•™ìƒë¸” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©
            vectorstore = get_vectorstore()
            return vectorstore.similarity_search(query, k=k)
    
    def _get_doc_id(self, doc):
        """ë¬¸ì„œì˜ ê³ ìœ  ID ìƒì„±"""
        # ë©”íƒ€ë°ì´í„°ì˜ id, type, chunk_indexë¥¼ ì¡°í•©í•˜ì—¬ ê³ ìœ  ID ìƒì„±
        doc_id = doc.metadata.get('id', 0)
        doc_type = doc.metadata.get('type', 'unknown')
        chunk_idx = doc.metadata.get('chunk_index', 0)
        return f"{doc_type}_{doc_id}_{chunk_idx}"


@tool
def semantic_search_tool(query: str) -> str:
    """
    ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ì„ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤ (BM25 + Vector ì•™ìƒë¸”).
    ì‚¬ìš©ìê°€ íŠ¹ì • ì£¼ì œë‚˜ í‚¤ì›Œë“œì— ëŒ€í•œ ê²Œì‹œê¸€ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ê²€ìƒ‰í•  ë‚´ìš© (ì˜ˆ: "ìœ¡ì•„ì— ëŒ€í•œ ê²Œì‹œê¸€", "ìš”ë¦¬ ë ˆì‹œí”¼")
        
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´ (ìƒìœ„ 10ê°œ ê²°ê³¼ í¬í•¨) + ê²Œì‹œê¸€ ID ëª©ë¡
    """
    try:
        # EnsembleRetriever ì‚¬ìš© (BM25 + Vector)
        ensemble_retriever = get_ensemble_retriever()
        
        # ì•™ìƒë¸” ê²€ìƒ‰ ìˆ˜í–‰
        results = ensemble_retriever.get_relevant_documents(query)
        
        if not results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ ë¶„ë¦¬ ë° ID ìˆ˜ì§‘
        board_ids = []
        comment_ids = []
        board_results = []
        comment_results = []
        
        for doc in results:
            doc_type = doc.metadata.get('type', 'board')
            doc_id = doc.metadata.get('id')
            
            if doc_type == 'board' and doc_id:
                if doc_id not in board_ids:
                    board_ids.append(doc_id)
                    board_results.append(doc)
            elif doc_type == 'comment' and doc_id:
                if doc_id not in comment_ids:
                    comment_ids.append(doc_id)
                    comment_results.append(doc)
        
        # ê²€ìƒ‰ ë©”íƒ€ë°ì´í„° ìƒì„±
        search_metadata = {
            'search_method': 'BM25+Vector ì•™ìƒë¸”',
            'total_results': len(results),
            'board_count': len(board_results),
            'comment_count': len(comment_results),
            'board_ids': board_ids,
            'comment_ids': comment_ids
        }
        
        # ê²°ê³¼ í¬ë§·íŒ…
        output = [f"'{query}'ì— ëŒ€í•œ ì•™ìƒë¸” ê²€ìƒ‰ ê²°ê³¼ {len(results)}ê±´ (ê²Œì‹œê¸€ {len(board_results)}ê°œ, ëŒ“ê¸€ {len(comment_results)}ê°œ):\n"]
        
        # ì „ì²´ ê²°ê³¼ í‘œì‹œ (ê²Œì‹œê¸€ + ëŒ“ê¸€)
        for idx, doc in enumerate(results, 1):
            title = doc.metadata.get('title', 'ì œëª© ì—†ìŒ')
            author = doc.metadata.get('author', 'ìµëª…')
            date = doc.metadata.get('date', 'N/A')
            doc_type = doc.metadata.get('type', 'board')
            
            # ì²­í¬ ì •ë³´ ì¶”ê°€
            chunk_info = ""
            if doc.metadata.get('chunk_count', 1) > 1:
                chunk_idx = doc.metadata.get('chunk_index', 0)
                chunk_count = doc.metadata.get('chunk_count', 1)
                chunk_info = f" (ì²­í¬ {chunk_idx+1}/{chunk_count})"
            
            type_text = "ğŸ“„ ê²Œì‹œê¸€" if doc_type == "board" else "ğŸ’¬ ëŒ“ê¸€"
            
            # ëŒ“ê¸€ì¸ ê²½ìš° ê²Œì‹œê¸€ ì œëª© í‘œì‹œ
            if doc_type == "comment":
                board_title = doc.metadata.get('board_title', 'ì œëª© ì—†ìŒ')
                title = f"[ëŒ“ê¸€] {board_title}"
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ìˆœì„œ ê¸°ë°˜)
            similarity_score = max(0, 100 - (idx * 5))
            
            output.append(f"\n[{idx}] {type_text} - {title}{chunk_info}")
            output.append(f"ì‘ì„±ì: {author} | ë‚ ì§œ: {date} | ìœ ì‚¬ë„: {similarity_score}% | ê²€ìƒ‰: BM25+Vector ì•™ìƒë¸”")
            output.append(f"ë‚´ìš©: {doc.page_content[:100]}...")
            output.append("-" * 50)
        
        # ê²Œì‹œê¸€ ID ëª©ë¡ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê²°ê³¼ì— í¬í•¨ (JSON í˜•íƒœë¡œ)
        if board_ids:
            # ì „ì—­ ë³€ìˆ˜ì— ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ (ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸°ì—ì„œ ì‚¬ìš©)
            global _last_search_board_ids
            _last_search_board_ids = board_ids.copy()
            
            output.append(f"\n[BOARD_IDS]: {json.dumps(board_ids)}")
            output.append(f"[SEARCH_QUERY]: {query}")
            output.append(f"[SEARCH_METADATA]: {json.dumps(search_metadata)}")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\n" \
               f"BM25 ì¸ë±ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° 'python embed_board_comments.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”."


@tool
def churn_analysis_tool(query: str) -> str:
    """
    ì‚¬ìš©ì ì´íƒˆ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    ì´íƒˆë¥ , ì´íƒˆ ì‚¬ìš©ì ìˆ˜, ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„ ë“±ì„ í™•ì¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ë¶„ì„ ìš”ì²­ ë‚´ìš© (ì˜ˆ: "ì´íƒˆë¥  ì•Œë ¤ì¤˜", "ì–´ë–¤ ì‚¬ìš©ìê°€ ì´íƒˆí•˜ë‚˜ìš”")
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ê¸°ê°„ ê³„ì‚° (ë°ì´í„°ê°€ ìˆëŠ” ê³¼ê±° ë‚ ì§œ ì‚¬ìš©)
    # 2025ë…„ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 2024ë…„ ë°ì´í„° ì‚¬ìš©
    now = datetime(2024, 12, 31)  # ë°ì´í„°ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‚ ì§œ
    end_month = now.strftime("%Y-%m")
    
    # 3ê°œì›” ì „ ê³„ì‚°
    start_date = now - timedelta(days=90)
    start_month = start_date.strftime("%Y-%m")
    
    # ì‹¤í–‰ ëª…ë ¹ JSON ìƒì„± (API ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)
    execution_data = {
        "action": "execute_analysis",
        "tool_id": "churn_analysis_tool",
        "api_endpoint": "/api/churn/analysis/run",
        "params": {
            "start_month": start_month,
            "end_month": end_month,
            "segments": {
                "gender": True,
                "age_band": True,
                "channel": True,
                "combined": False,
                "weekday_pattern": False,
                "time_pattern": False,
                "action_type": False
            },
            "inactivity_days": [30, 60, 90],
            "threshold": 1
        },
        "message": f"ì´íƒˆ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ê¸°ê°„: {start_month} ~ {end_month})"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def ethics_check_tool(query: str) -> str:
    """
    ë¹„ìœ¤ë¦¬ì  ê²Œì‹œê¸€ ë° ìŠ¤íŒ¸ ì§€ìˆ˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    ìš•ì„¤, ë¹„ë°©, ìŠ¤íŒ¸, ê´‘ê³  ë“±ì˜ ë¬¸ì œ ê²Œì‹œê¸€ í†µê³„ë¥¼ í™•ì¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ì¡°íšŒ ìš”ì²­ ë‚´ìš© (ì˜ˆ: "ë¹„ìœ¤ë¦¬ì ì¸ ê²Œì‹œê¸€ ìˆì–´?", "ìŠ¤íŒ¸ ì–¼ë§ˆë‚˜ ìˆì–´?")
        
    Returns:
        ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ ê²°ê³¼ ë¬¸ìì—´ + í˜ì´ì§€ URL
    """
    try:
        # ethics_logs í…Œì´ë¸”ì—ì„œ ì‹¤ì œ ë°ì´í„° ì¡°íšŒ (ê°„ë‹¨í•œ í†µê³„)
        from app.database import execute_query
        
        # ìµœê·¼ ë¹„ìœ¤ë¦¬ ë¡œê·¸ í†µê³„
        high_risk = execute_query(
            "SELECT COUNT(*) as count FROM ethics_logs WHERE score >= 70",
            fetch_one=True
        )
        
        spam = execute_query(
            "SELECT COUNT(*) as count FROM ethics_logs WHERE spam >= 70",
            fetch_one=True
        )
        
        total = execute_query(
            "SELECT COUNT(*) as count FROM ethics_logs",
            fetch_one=True
        )
        
        high_risk_count = high_risk['count'] if high_risk else 0
        spam_count = spam['count'] if spam else 0
        total_count = total['count'] if total else 0
        
        if total_count == 0:
            return """âš ï¸ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„:
            
ì•„ì§ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.
ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ì„ ì‘ì„±í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /ethics_dashboard]"""
        
        return f"""âš ï¸ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ ê²°ê³¼:

ğŸ“Š ì „ì²´ í†µê³„:
â€¢ ë¶„ì„ëœ ì½˜í…ì¸ : {total_count:,}ê±´
â€¢ ê³ ìœ„í—˜ ì½˜í…ì¸ : {high_risk_count}ê±´ ({high_risk_count/total_count*100:.1f}%)
â€¢ ìŠ¤íŒ¸ ê°ì§€: {spam_count}ê±´

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ê³¼ ì „ì²´ ëª©ë¡ì€ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /ethics_dashboard]"""
        
    except Exception as e:
        return f"""âš ï¸ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„:
        
ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /ethics_dashboard]"""


@tool
def match_reports_tool(query: str) -> str:
    """
    ì‹ ê³  ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ì‹ ê³  ìœ í˜•ë³„ ê±´ìˆ˜, ì²˜ë¦¬ ìƒíƒœ ë“±ì„ í™•ì¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ì¡°íšŒ ìš”ì²­ ë‚´ìš© (ì˜ˆ: "ì‹ ê³  ë§ì€ ê²Œì‹œê¸€", "ì‹ ê³  í†µê³„ ë³´ì—¬ì¤˜")
        
    Returns:
        ì‹ ê³  í†µê³„ ë¬¸ìì—´ + í˜ì´ì§€ URL
    """
    try:
        # report í…Œì´ë¸”ì—ì„œ ì‹¤ì œ ë°ì´í„° ì¡°íšŒ
        from app.database import execute_query
        
        # ì „ì²´ ì‹ ê³  ê±´ìˆ˜
        total_result = execute_query(
            "SELECT COUNT(*) as count FROM report",
            fetch_one=True
        )
        total = total_result['count'] if total_result else 0
        
        if total == 0:
            return """ğŸš¨ ì‹ ê³  ë°ì´í„° í†µê³„:

ì•„ì§ ì‹ ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ì‹ ê³  ë‚´ì—­ê³¼ ë¶„ì„ì€ ì‹ ê³  ë¶„ë¥˜ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /reports]"""
        
        # ì²˜ë¦¬ ìƒíƒœë³„ í†µê³„
        status_stats = execute_query(
            "SELECT status, COUNT(*) as count FROM report GROUP BY status",
            fetch_all=True
        )
        
        # ì‹ ê³  ìœ í˜•ë³„ í†µê³„ (ìƒìœ„ 5ê°œ)
        type_stats = execute_query(
            "SELECT report_type, COUNT(*) as count FROM report GROUP BY report_type ORDER BY count DESC LIMIT 5",
            fetch_all=True
        )
        
        output = [f"""ğŸš¨ ì‹ ê³  ë°ì´í„° í†µê³„:

ğŸ“Š ì „ì²´ ì‹ ê³ : {total}ê±´

ì²˜ë¦¬ ìƒíƒœ:"""]
        
        status_names = {
            'pending': 'ëŒ€ê¸° ì¤‘',
            'reviewing': 'ê²€í†  ì¤‘',
            'completed': 'ì²˜ë¦¬ ì™„ë£Œ',
            'rejected': 'ê±°ë¶€ë¨'
        }
        
        for stat in status_stats:
            status_name = status_names.get(stat['status'], stat['status'])
            output.append(f"â€¢ {status_name}: {stat['count']}ê±´")
        
        output.append("\nì‹ ê³  ìœ í˜•ë³„ TOP 5:")
        for idx, stat in enumerate(type_stats, 1):
            percentage = (stat['count'] / total * 100) if total > 0 else 0
            output.append(f"{idx}. {stat['report_type']}: {stat['count']}ê±´ ({percentage:.1f}%)")
        
        output.append("\nğŸ’¡ ìì„¸í•œ ì‹ ê³  ë‚´ì—­ê³¼ ë¶„ì„ì€ ì‹ ê³  ë¶„ë¥˜ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        output.append("[í˜ì´ì§€ ì´ë™: /reports]")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"""ğŸš¨ ì‹ ê³  í†µê³„:
        
ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ ì‹ ê³  í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /reports]"""


@tool
def trends_analysis_tool(query: str) -> str:
    """
    íŠ¸ë Œë“œ í‚¤ì›Œë“œì™€ ì¸ê¸° ê²€ìƒ‰ì–´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    ì¸ê¸° í‚¤ì›Œë“œ, ê¸‰ìƒìŠ¹ í‚¤ì›Œë“œ, íŠ¸ë Œë“œ ë³€í™” ë“±ì„ í™•ì¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ë¶„ì„ ìš”ì²­ ë‚´ìš© (ì˜ˆ: "íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì•Œë ¤ì¤˜", "ì¸ê¸° ê²€ìƒ‰ì–´ëŠ”?")
        
    Returns:
        íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ë¬¸ìì—´ + í˜ì´ì§€ URL
    """
    try:
        # board í…Œì´ë¸”ì—ì„œ ìµœê·¼ ì¸ê¸° ê²Œì‹œê¸€ ë¶„ì„
        from app.database import execute_query
        
        # ìµœê·¼ ì¡°íšŒìˆ˜ ë†’ì€ ê²Œì‹œê¸€ì˜ ì¹´í…Œê³ ë¦¬ í†µê³„
        category_stats = execute_query(
            """SELECT category, COUNT(*) as count, SUM(view_count) as total_views 
               FROM board 
               WHERE status='exposed' 
               GROUP BY category 
               ORDER BY total_views DESC 
               LIMIT 5""",
            fetch_all=True
        )
        
        if not category_stats or len(category_stats) == 0:
            return """ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„:

ì•„ì§ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ íŠ¸ë Œë“œ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /trends]"""
        
        output = ["""ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼:

ğŸ”¥ ì¸ê¸° ì¹´í…Œê³ ë¦¬ TOP 5:"""]
        
        for idx, stat in enumerate(category_stats, 1):
            output.append(f"{idx}. {stat['category']}: ê²Œì‹œê¸€ {stat['count']}ê°œ, ì´ ì¡°íšŒìˆ˜ {stat['total_views']:,}íšŒ")
        
        output.append("\nğŸ’¡ ìì„¸í•œ íŠ¸ë Œë“œ ë¶„ì„ê³¼ ì‹œê°í™”ëŠ” íŠ¸ë Œë“œ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        output.append("[í˜ì´ì§€ ì´ë™: /trends]")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"""ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„:
        
ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ íŠ¸ë Œë“œ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[í˜ì´ì§€ ì´ë™: /trends]"""


@tool
def execute_churn_analysis_tool(period_months: int = 3) -> str:
    """
    ì‚¬ìš©ì ì´íƒˆ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. 
    ì‚¬ìš©ìê°€ "ì´íƒˆ ë¶„ì„ ì‹¤í–‰í•´ì¤˜", "ë¶„ì„ ëŒë ¤ì¤˜" ê°™ì€ ëª…ë ¹ì„ í•˜ë©´ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        period_months: ë¶„ì„í•  ê¸°ê°„ (ê°œì›” ìˆ˜, ê¸°ë³¸ê°’ 3ê°œì›”)
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ê¸°ê°„ ê³„ì‚° (ë°ì´í„°ê°€ ìˆëŠ” ê³¼ê±° ë‚ ì§œ ì‚¬ìš©)
    # 2025ë…„ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 2024ë…„ ë°ì´í„° ì‚¬ìš©
    now = datetime(2024, 12, 31)  # ë°ì´í„°ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‚ ì§œ
    end_month = now.strftime("%Y-%m")
    
    # period_months ê°œì›” ì „ ê³„ì‚°
    start_date = now - timedelta(days=30 * period_months)
    start_month = start_date.strftime("%Y-%m")
    
    # ì‹¤í–‰ ëª…ë ¹ JSON ìƒì„± (API ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)
    execution_data = {
        "action": "execute_analysis",
        "tool_id": "churn_analysis_tool",
        "api_endpoint": "/api/churn/analysis/run",
        "params": {
            "start_month": start_month,
            "end_month": end_month,
            "segments": {
                "gender": True,
                "age_band": True,
                "channel": True,
                "combined": False,
                "weekday_pattern": False,
                "time_pattern": False,
                "action_type": False
            },
            "inactivity_days": [30, 60, 90],
            "threshold": 1
        },
        "message": f"ì´íƒˆ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ê¸°ê°„: {start_month} ~ {end_month})"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def execute_ethics_analysis_tool(text: str) -> str:
    """
    ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ íŠ¹ì • í…ìŠ¤íŠ¸ì— ëŒ€í•´ "ë¹„ìœ¤ë¦¬ ë¶„ì„í•´ì¤˜", "ìŠ¤íŒ¸ ì²´í¬í•´ì¤˜" ê°™ì€ ëª…ë ¹ì„ í•˜ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë‚´ìš©
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    execution_data = {
        "action": "execute_analysis",
        "tool_id": "ethics_check_tool",
        "api_endpoint": "/api/ethics/analyze",
        "params": {
            "text": text
        },
        "message": f"ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def approve_report_tool(report_id: int, note: str = "") -> str:
    """
    ì‹ ê³ ë¥¼ ìŠ¹ì¸í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ "id #18 ìŠ¹ì¸í•´ì¤˜", "ì‹ ê³  18ë²ˆ ìŠ¹ì¸" ê°™ì€ ëª…ë ¹ì„ í•˜ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        report_id: ì‹ ê³  ID
        note: ì²˜ë¦¬ ì‚¬ìœ  (ì„ íƒ)
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    params = {"action": "approve"}
    if note:  # noteê°€ ìˆì„ ë•Œë§Œ í¬í•¨
        params["note"] = note
    
    execution_data = {
        "action": "execute_action",
        "tool_id": "approve_report_tool",
        "api_endpoint": f"/api/admin/reports/{report_id}/process",
        "params": params,
        "message": f"ì‹ ê³  #{report_id}ë¥¼ ìŠ¹ì¸í•©ë‹ˆë‹¤"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def reject_report_tool(report_id: int, note: str = "") -> str:
    """
    ì‹ ê³ ë¥¼ ê±°ë¶€í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ "id #18 ê±°ë¶€í•´ì¤˜", "ì‹ ê³  18ë²ˆ ê±°ë¶€" ê°™ì€ ëª…ë ¹ì„ í•˜ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        report_id: ì‹ ê³  ID
        note: ì²˜ë¦¬ ì‚¬ìœ  (ì„ íƒ)
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    params = {"action": "reject"}
    if note:  # noteê°€ ìˆì„ ë•Œë§Œ í¬í•¨
        params["note"] = note
    
    execution_data = {
        "action": "execute_action",
        "tool_id": "reject_report_tool",
        "api_endpoint": f"/api/admin/reports/{report_id}/process",
        "params": params,
        "message": f"ì‹ ê³  #{report_id}ë¥¼ ê±°ë¶€í•©ë‹ˆë‹¤"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def filter_reports_tool(status: str = "all") -> str:
    """
    ì‹ ê³  ëª©ë¡ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ "ëŒ€ê¸°ì¤‘ ì‹ ê³  ë³´ì—¬ì¤˜", "ìŠ¹ì¸ëœ ì‹ ê³  í™•ì¸", "ê±°ë¶€ëœ ì‹ ê³ ", "ì „ì²´ ì‹ ê³ " ê°™ì€ ëª…ë ¹ì„ í•˜ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        status: í•„í„° ìƒíƒœ - "pending"(ëŒ€ê¸°ì¤‘), "approved"(ìŠ¹ì¸), "rejected"(ê±°ë¶€), "all"(ì „ì²´)
        
    Returns:
        í•„í„°ë§ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    # í•œê¸€ ìƒíƒœëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜
    status_map = {
        "ëŒ€ê¸°ì¤‘": "pending",
        "ëŒ€ê¸°": "pending",
        "ìŠ¹ì¸": "approved",
        "ìŠ¹ì¸ëœ": "approved",
        "ê±°ë¶€": "rejected",
        "ê±°ë¶€ëœ": "rejected",
        "ì „ì²´": "all",
        "ëª¨ë“ ": "all",
        "ëª¨ë‘": "all"
    }
    
    filter_status = status_map.get(status, status)
    
    # ìƒíƒœ í‘œì‹œëª…
    status_display = {
        "pending": "ëŒ€ê¸°ì¤‘",
        "approved": "ìŠ¹ì¸",
        "rejected": "ê±°ë¶€",
        "all": "ì „ì²´"
    }.get(filter_status, "ì „ì²´")
    
    execution_data = {
        "action": "filter_reports",
        "tool_id": "match_reports_tool",
        "api_endpoint": "/api/admin/reports",
        "filter_params": {
            "status": filter_status if filter_status != "all" else "",
            "type": ""
        },
        "message": f"{status_display} ì‹ ê³  ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤"
    }
    
    return json.dumps(execution_data, ensure_ascii=False)


@tool
def board_navigation_tool(
    action: str,
    search_query: str = None,
    category: str = None,
    sort_by: str = "latest",
    page: int = 1
) -> str:
    """
    ê²Œì‹œíŒ í•„í„°ë§, ì •ë ¬, í˜ì´ì§€ ì´ë™ì„ ì œì–´í•©ë‹ˆë‹¤.
    
    Args:
        action: ìˆ˜í–‰í•  ì•¡ì…˜ ("filter", "sort", "page")
        search_query: ê²€ìƒ‰ì–´ (actionì´ "filter"ì¼ ë•Œ ì‚¬ìš©)
        category: ì¹´í…Œê³ ë¦¬ í•„í„° ("", "free", "notice", "qna", "review", "tips")
        sort_by: ì •ë ¬ ë°©ì‹ ("latest", "popular", "similarity")
        page: í˜ì´ì§€ ë²ˆí˜¸ (actionì´ "page"ì¼ ë•Œ ì‚¬ìš©)
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    try:
        # ì•¡ì…˜ë³„ ì²˜ë¦¬
        if action == "filter":
            if search_query:
                # ê²€ìƒ‰ì–´ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰
                return semantic_search_tool(search_query)
            else:
                # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ë§Œ
                execution_data = {
                    "action_type": "execute",
                    "tool_id": "board_navigation_tool",
                    "action": "filter_category",
                    "params": {
                        "category": category or ""
                    },
                    "message": f"{'ì „ì²´' if not category else category} ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤"
                }
        
        elif action == "sort":
            sort_labels = {
                "latest": "ìµœì‹ ìˆœ",
                "popular": "ì¸ê¸°ìˆœ", 
                "similarity": "ìœ ì‚¬ë„ìˆœ"
            }
            execution_data = {
                "action_type": "execute",
                "tool_id": "board_navigation_tool",
                "action": "change_sort",
                "params": {
                    "sort_by": sort_by
                },
                "message": f"{sort_labels.get(sort_by, sort_by)}ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤"
            }
        
        elif action == "page":
            execution_data = {
                "action_type": "execute",
                "tool_id": "board_navigation_tool", 
                "action": "navigate_page",
                "params": {
                    "page": page
                },
                "message": f"{page}í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤"
            }
        
        else:
            return f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜ì…ë‹ˆë‹¤: {action}"
        
        return json.dumps(execution_data, ensure_ascii=False)
        
    except Exception as e:
        return f"ê²Œì‹œíŒ ì¡°ì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
def board_detail_tool(
    post_id: int = None,
    relative_position: str = None,
    search_context: str = None
) -> str:
    """
    íŠ¹ì • ê²Œì‹œê¸€ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        post_id: ê²Œì‹œê¸€ ID (ì§ì ‘ ì§€ì •)
        relative_position: ìƒëŒ€ì  ìœ„ì¹˜ ("ì²«ë²ˆì§¸", "ë‘ë²ˆì§¸", "ì„¸ë²ˆì§¸", "ë„¤ë²ˆì§¸", "ë‹¤ì„¯ë²ˆì§¸" ë“±)
        search_context: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ (ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒí•  ë•Œ ì‚¬ìš©)
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    try:
        # ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ìˆ«ìë¡œ ë³€í™˜
        position_map = {
            "ì²«ë²ˆì§¸": 1, "ì²«ì§¸": 1, "1ë²ˆì§¸": 1, "first": 1,
            "ë‘ë²ˆì§¸": 2, "ë‘˜ì§¸": 2, "2ë²ˆì§¸": 2, "second": 2,
            "ì„¸ë²ˆì§¸": 3, "ì…‹ì§¸": 3, "3ë²ˆì§¸": 3, "third": 3,
            "ë„¤ë²ˆì§¸": 4, "ë„·ì§¸": 4, "4ë²ˆì§¸": 4, "fourth": 4,
            "ë‹¤ì„¯ë²ˆì§¸": 5, "ë‹¤ì„¯ì§¸": 5, "5ë²ˆì§¸": 5, "fifth": 5,
            "ì—¬ì„¯ë²ˆì§¸": 6, "ì—¬ì„¯ì§¸": 6, "6ë²ˆì§¸": 6, "sixth": 6,
            "ì¼ê³±ë²ˆì§¸": 7, "ì¼ê³±ì§¸": 7, "7ë²ˆì§¸": 7, "seventh": 7,
            "ì—¬ëŸë²ˆì§¸": 8, "ì—¬ëŸì§¸": 8, "8ë²ˆì§¸": 8, "eighth": 8,
            "ì•„í™‰ë²ˆì§¸": 9, "ì•„í™‰ì§¸": 9, "9ë²ˆì§¸": 9, "ninth": 9,
            "ì—´ë²ˆì§¸": 10, "ì—´ì§¸": 10, "10ë²ˆì§¸": 10, "tenth": 10
        }
        
        position_number = None
        if relative_position:
            position_number = position_map.get(relative_position.lower())
        
        # ì§ì ‘ IDê°€ ì§€ì •ë˜ì§€ ì•Šê³  ìƒëŒ€ì  ìœ„ì¹˜ê°€ ìˆëŠ” ê²½ìš°, ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì°¾ê¸°
        if not post_id and position_number:
            # ì „ì—­ ë³€ìˆ˜ë¡œ ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ (ê°„ë‹¨í•œ êµ¬í˜„)
            global _last_search_board_ids
            if '_last_search_board_ids' in globals() and _last_search_board_ids:
                if position_number <= len(_last_search_board_ids):
                    post_id = _last_search_board_ids[position_number - 1]
                else:
                    return f"ê²€ìƒ‰ ê²°ê³¼ì— {relative_position} ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. (ì´ {len(_last_search_board_ids)}ê°œ ê²°ê³¼)"
            else:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²Œì‹œê¸€ ID ì‚¬ìš© (ë°ëª¨ìš©)
                # ì‹¤ì œë¡œëŠ” ìµœì‹  ê²Œì‹œê¸€ì„ ì¡°íšŒí•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ position_numberë¥¼ IDë¡œ ì‚¬ìš©
                post_id = position_number
                print(f"[DEBUG] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ê¸°ë³¸ ID ì‚¬ìš©: {post_id}")
        
        if not post_id and not relative_position:
            return "ê²Œì‹œê¸€ ID ë˜ëŠ” ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”."
        
        if not post_id:
            return f"'{relative_position}' ìœ„ì¹˜ì˜ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        execution_data = {
            "action_type": "execute",
            "action": "show_post_detail",
            "tool_id": "board_detail_tool",
            "execution_data": {
                "action": "show_post_detail",
                "tool_id": "board_detail_tool",
                "params": {
                    "post_id": post_id,
                    "relative_position": relative_position
                },
                "message": f"{'ê²Œì‹œê¸€ ' + str(post_id) + 'ë²ˆ' if post_id else relative_position + ' ê²Œì‹œê¸€'}ì˜ ìƒì„¸ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤"
            }
        }
        
        return json.dumps(execution_data, ensure_ascii=False)
        
    except Exception as e:
        return f"ê²Œì‹œê¸€ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
def board_filter_tool(
    category: str = "",
    sort_by: str = "latest"
) -> str:
    """
    ê²Œì‹œíŒì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í•„í„°ë§í•˜ê³  ì •ë ¬í•©ë‹ˆë‹¤.
    
    Args:
        category: ì¹´í…Œê³ ë¦¬ ("", "free", "notice", "qna", "review", "tips")
        sort_by: ì •ë ¬ ë°©ì‹ ("latest", "popular", "similarity")
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    try:
        category_labels = {
            "": "ì „ì²´",
            "free": "ììœ ê²Œì‹œíŒ",
            "notice": "ê³µì§€ì‚¬í•­", 
            "qna": "ì§ˆë¬¸ë‹µë³€",
            "review": "í›„ê¸°",
            "tips": "íŒ/ë…¸í•˜ìš°"
        }
        
        sort_labels = {
            "latest": "ìµœì‹ ìˆœ",
            "popular": "ì¸ê¸°ìˆœ",
            "similarity": "ìœ ì‚¬ë„ìˆœ"
        }
        
        execution_data = {
            "action_type": "execute",
            "tool_id": "board_filter_tool",
            "action": "filter_and_sort",
            "params": {
                "category": category,
                "sort_by": sort_by
            },
            "message": f"{category_labels.get(category, 'ì „ì²´')} ì¹´í…Œê³ ë¦¬ë¥¼ {sort_labels.get(sort_by, sort_by)}ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤"
        }
        
        return json.dumps(execution_data, ensure_ascii=False)
        
    except Exception as e:
        return f"ê²Œì‹œíŒ í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool  
def board_page_tool(page: int) -> str:
    """
    ê²Œì‹œíŒì˜ íŠ¹ì • í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    
    Args:
        page: ì´ë™í•  í˜ì´ì§€ ë²ˆí˜¸
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    try:
        if page < 1:
            return "í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        
        execution_data = {
            "action_type": "execute",
            "tool_id": "board_page_tool",
            "action": "navigate_page",
            "params": {
                "page": page
            },
            "message": f"{page}í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤"
        }
        
        return json.dumps(execution_data, ensure_ascii=False)
        
    except Exception as e:
        return f"í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
def board_list_tool(request_type: str = "back_to_list") -> str:
    """
    ê²Œì‹œíŒ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ í‘œì‹œí•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ "ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ ë‹¬ë¼", "ë’¤ë¡œ", "ê²€ìƒ‰ ê²°ê³¼ ë³´ì—¬ì¤˜" ë“±ì˜ ëª…ë ¹ì„ í•˜ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        request_type: ìš”ì²­ íƒ€ì… ("back_to_list", "show_search_results", "show_board_list")
        
    Returns:
        ì‹¤í–‰ ëª…ë ¹ JSON ë¬¸ìì—´
    """
    try:
        # ìš”ì²­ íƒ€ì…ë³„ ë©”ì‹œì§€ ì„¤ì •
        message_map = {
            "back_to_list": "ì´ì „ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤",
            "show_search_results": "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ í‘œì‹œí•©ë‹ˆë‹¤", 
            "show_board_list": "ê²Œì‹œíŒ ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤"
        }
        
        message = message_map.get(request_type, "ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤")
        
        execution_data = {
            "action": "back_to_list",
            "tool_id": "board_list_tool",
            "params": {
                "request_type": request_type
            },
            "message": message
        }
        
        return json.dumps(execution_data, ensure_ascii=False)
        
    except Exception as e:
        return f"ëª©ë¡ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
def daily_report_tool(query: str) -> str:
    """
    ì˜¤ëŠ˜ì˜ ì¼ì¼ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    "ì˜¤ëŠ˜ì˜ í• ì¼", "ì¼ì¼ ë³´ê³ ì„œ", "ì˜¤ëŠ˜ì˜ ì—…ë¬´", "ë°ì¼ë¦¬ ë¦¬í¬íŠ¸" ë“±ì˜ ëª…ë ¹ì— ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ë³´ê³ ì„œ ìš”ì²­ (ì˜ˆ: "ì˜¤ëŠ˜ì˜ í• ì¼ ë³´ì—¬ì¤˜")
        
    Returns:
        ì¼ì¼ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ (ì‹ ê³  í˜„í™©, ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ í†µê³„, ì´íƒˆë¥ , íŠ¸ë Œë“œ)
    """
    try:
        from datetime import datetime
        from app.database import execute_query
        
        # ìˆ«ì í¬ë§·íŒ… í•¨ìˆ˜
        def format_number(num):
            """ìˆ«ìë¥¼ K, M ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
            if num >= 1000000:
                return f"{num/1000000:.1f}M"
            elif num >= 1000:
                return f"{num/1000:.1f}K"
            else:
                return f"{num:,}"
        
        # í˜„ì¬ ë‚ ì§œ
        today = datetime.now().strftime("%Y-%m-%d")
        weekday_names = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
        weekday = weekday_names[datetime.now().weekday()]
        today_display = datetime.now().strftime(f"%Yë…„ %mì›” %dì¼ ({weekday})")
        
        report_lines = []
        report_lines.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append("â•‘          ğŸ“‹ ì»¤ë®¤ë‹ˆí‹° ì¼ì¼ ìš´ì˜ ë³´ê³ ì„œ              â•‘")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append(f"â•‘          {today_display:^30}           â•‘")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        report_lines.append("")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # 1. ì‹ ê³  ë° ì²˜ë¦¬ í˜„í™©
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        try:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“¢ ì‹ ê³  ë° ì²˜ë¦¬ í˜„í™©                           â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            
            # ì „ì²´ ì‹ ê³  ê±´ìˆ˜
            total_result = execute_query(
                "SELECT COUNT(*) as count FROM report",
                fetch_one=True
            )
            total_reports = total_result['count'] if total_result else 0
            
            # ì²˜ë¦¬ ìƒíƒœë³„ í†µê³„
            status_stats = execute_query(
                "SELECT status, COUNT(*) as count FROM report GROUP BY status",
                fetch_all=True
            )
            
            status_counts = {
                'pending': 0,
                'reviewing': 0,
                'completed': 0,
                'rejected': 0
            }
            
            if status_stats:
                for stat in status_stats:
                    status_counts[stat['status']] = stat['count']
            
            # ì˜¤ëŠ˜ ì ‘ìˆ˜ëœ ì‹ ê³ 
            today_reported = execute_query(
                f"SELECT COUNT(*) as count FROM report WHERE DATE(created_at) = '{today}'",
                fetch_one=True
            )
            today_reports = today_reported['count'] if today_reported else 0
            
            # ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ì‹ ê³ 
            today_processed = execute_query(
                f"SELECT COUNT(*) as count FROM report WHERE DATE(processed_date) = '{today}'",
                fetch_one=True
            )
            today_processed_count = today_processed['count'] if today_processed else 0
            
            # ì „ì²´ í†µê³„
            report_lines.append("  [ì „ì²´ ì‹ ê³  í˜„í™©]")
            report_lines.append(f"  â€¢ ì´ ì‹ ê³  ê±´ìˆ˜: {total_reports:,}ê±´")
            report_lines.append("")
            report_lines.append("  [ìƒíƒœë³„ ë¶„ë¥˜]")
            report_lines.append(f"    â³ ëŒ€ê¸°ì¤‘:    {status_counts['pending']:>4}ê±´")
            report_lines.append(f"    âœ… ì²˜ë¦¬ì™„ë£Œ:  {status_counts['completed']:>4}ê±´")
            report_lines.append(f"    âŒ ê±°ë¶€ë¨:    {status_counts['rejected']:>4}ê±´")
            report_lines.append("")
            report_lines.append("  [ì˜¤ëŠ˜ì˜ í™œë™]")
            report_lines.append(f"    ğŸ“¥ ì‹ ê·œ ì ‘ìˆ˜: {today_reports:>4}ê±´")
            report_lines.append(f"    âœ”ï¸  ì²˜ë¦¬ ì™„ë£Œ: {today_processed_count:>4}ê±´")
            report_lines.append("")
            
            if status_counts['pending'] > 10:
                report_lines.append("  âš ï¸  ì£¼ì˜: ëŒ€ê¸°ì¤‘ì¸ ì‹ ê³ ê°€ 10ê±´ ì´ìƒì…ë‹ˆë‹¤!")
                report_lines.append("")
            
        except Exception as e:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“¢ ì‹ ê³  ë° ì²˜ë¦¬ í˜„í™©                           â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            report_lines.append(f"  âš ï¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            report_lines.append("")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # 2. ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„í†µê³„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        try:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  âš ï¸  ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ í†µê³„                      â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            
            # ì „ì²´ ë¶„ì„ëœ ì½˜í…ì¸ 
            total_ethics = execute_query(
                "SELECT COUNT(*) as count FROM ethics_logs",
                fetch_one=True
            )
            total_ethics_count = total_ethics['count'] if total_ethics else 0
            
            # ê³ ìœ„í—˜ ì½˜í…ì¸ 
            high_risk = execute_query(
                "SELECT COUNT(*) as count FROM ethics_logs WHERE score >= 70",
                fetch_one=True
            )
            high_risk_count = high_risk['count'] if high_risk else 0
            
            # ìŠ¤íŒ¸ ê°ì§€
            spam = execute_query(
                "SELECT COUNT(*) as count FROM ethics_logs WHERE spam >= 70",
                fetch_one=True
            )
            spam_count = spam['count'] if spam else 0
            
            # ì˜¤ëŠ˜ ë¶„ì„ëœ ì½˜í…ì¸ 
            today_ethics = execute_query(
                f"SELECT COUNT(*) as count FROM ethics_logs WHERE DATE(created_at) = '{today}'",
                fetch_one=True
            )
            today_ethics_count = today_ethics['count'] if today_ethics else 0
            
            high_risk_pct = (high_risk_count / total_ethics_count * 100) if total_ethics_count > 0 else 0
            spam_pct = (spam_count / total_ethics_count * 100) if total_ethics_count > 0 else 0
            
            # ìœ„í—˜ë„ íŒë‹¨
            risk_emoji = "ğŸŸ¢" if high_risk_pct < 3 else "ğŸŸ¡" if high_risk_pct < 5 else "ğŸ”´"
            
            report_lines.append("  [ì „ì²´ ë¶„ì„ í˜„í™©]")
            report_lines.append(f"  â€¢ ë¶„ì„ëœ ì½˜í…ì¸ : {format_number(total_ethics_count)}ê±´")
            report_lines.append("")
            report_lines.append("  [ìœ„í—˜ ì½˜í…ì¸  ê°ì§€]")
            report_lines.append(f"    {risk_emoji} ê³ ìœ„í—˜ ì½˜í…ì¸ : {high_risk_count:>4}ê±´ ({high_risk_pct:>5.1f}%)")
            report_lines.append(f"    ğŸš« ìŠ¤íŒ¸ ê°ì§€:     {spam_count:>4}ê±´ ({spam_pct:>5.1f}%)")
            report_lines.append("")
            report_lines.append("  [ì˜¤ëŠ˜ì˜ ë¶„ì„]")
            report_lines.append(f"    ğŸ” ë¶„ì„ ê±´ìˆ˜:     {today_ethics_count:>4}ê±´")
            report_lines.append("")
            
            if high_risk_pct >= 5:
                report_lines.append("  ğŸ”´ ê²½ê³ : ê³ ìœ„í—˜ ì½˜í…ì¸  ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤!")
                report_lines.append("  ğŸ’¡ /ethics_dashboard ì—ì„œ ìƒì„¸ í™•ì¸ í•„ìš”")
                report_lines.append("")
            
        except Exception as e:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  âš ï¸  ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸ ë¶„ì„ í†µê³„                      â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            report_lines.append(f"  âš ï¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            report_lines.append("")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # 3. ì´íƒˆë¥  ì²´í¬
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        try:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“‰ ì‚¬ìš©ì ì´íƒˆë¥  ë¶„ì„                          â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            
            # ì´íƒˆ ë¶„ì„ ì‹¤í–‰ (ê°„ëµ ë²„ì „)
            try:
                from chrun_backend.chrun_analytics import ChurnAnalyzer
                from chrun_backend.chrun_database import get_db
                
                db = next(get_db())
                analyzer = ChurnAnalyzer(db)
                
                # ìµœê·¼ 2ê°œì›” ë°ì´í„°ë¡œ ë¶„ì„
                end_date = datetime.now()
                start_date = end_date - timedelta(days=60)
                
                start_month = start_date.strftime("%Y-%m")
                end_month = end_date.strftime("%Y-%m")
                
                result = analyzer.run_full_analysis(
                    start_month=start_month,
                    end_month=end_month,
                    segments={
                        "gender": False,
                        "age_band": False,
                        "channel": False,
                        "combined": False,
                        "weekday_pattern": False,
                        "time_pattern": False,
                        "action_type": False
                    },
                    inactivity_days=[30, 60, 90],
                    threshold=1
                )
                
                metrics = result.get("metrics", {})
                insights = result.get("insights", [])
                
                churn_rate = metrics.get("churn_rate", 0)
                churned_users = metrics.get("churned_users", 0)
                active_users = metrics.get("active_users", 0)
                
                # ì´íƒˆë¥  ìƒíƒœ íŒë‹¨
                churn_emoji = "ğŸŸ¢" if churn_rate < 10 else "ğŸŸ¡" if churn_rate < 20 else "ğŸ”´"
                churn_status = "ì–‘í˜¸" if churn_rate < 10 else "ì£¼ì˜" if churn_rate < 20 else "ìœ„í—˜"
                
                report_lines.append("  [ì´íƒˆë¥  í˜„í™©]")
                report_lines.append(f"  {churn_emoji} í˜„ì¬ ì´íƒˆë¥ : {churn_rate:>6.1f}% ({churn_status})")
                report_lines.append("")
                report_lines.append("  [ì‚¬ìš©ì í†µê³„]")
                report_lines.append(f"    ğŸ‘¥ í™œì„± ì‚¬ìš©ì: {format_number(active_users):>6}ëª…")
                report_lines.append(f"    ğŸ‘¤ ì´íƒˆ ì‚¬ìš©ì: {format_number(churned_users):>6}ëª…")
                report_lines.append("")
                
                if insights and len(insights) > 0:
                    report_lines.append("  [ì£¼ìš” ì¸ì‚¬ì´íŠ¸]")
                    # ì²« ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸ë§Œ í‘œì‹œ (ìµœëŒ€ 70ì)
                    insight_text = insights[0][:70]
                    if len(insights[0]) > 70:
                        insight_text += "..."
                    report_lines.append(f"    ğŸ’¡ {insight_text}")
                    report_lines.append("")
                
                if churn_rate >= 20:
                    report_lines.append("  ğŸ”´ ê²½ê³ : ì´íƒˆë¥ ì´ ë†’ìŠµë‹ˆë‹¤!")
                    report_lines.append("  ğŸ’¡ /churn ì—ì„œ ìƒì„¸ ë¶„ì„ ë° ëŒ€ì‘ ë°©ì•ˆ í™•ì¸")
                    report_lines.append("")
                else:
                    report_lines.append("  ğŸ’¡ ìì„¸í•œ ë‚´ìš©: /churn")
                    report_lines.append("")
                
            except Exception as churn_error:
                # ì´íƒˆ ë¶„ì„ ì‹¤íŒ¨ ì‹œ
                report_lines.append("  [ì´íƒˆë¥  í˜„í™©]")
                report_lines.append("  â³ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                report_lines.append("")
                report_lines.append("  ğŸ’¡ ìì„¸í•œ ë‚´ìš©: /churn")
                report_lines.append("")
                
        except Exception as e:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“‰ ì‚¬ìš©ì ì´íƒˆë¥  ë¶„ì„                          â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            report_lines.append(f"  âš ï¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            report_lines.append("")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # 4. ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        try:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“ˆ ì»¤ë®¤ë‹ˆí‹° íŠ¸ë Œë“œ ë¶„ì„                        â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            
            # ìµœê·¼ ì¡°íšŒìˆ˜ ë†’ì€ ê²Œì‹œê¸€ì˜ ì¹´í…Œê³ ë¦¬ í†µê³„
            category_stats = execute_query(
                """SELECT category, COUNT(*) as count, SUM(view_count) as total_views 
                   FROM board 
                   WHERE status='exposed' 
                   GROUP BY category 
                   ORDER BY total_views DESC 
                   LIMIT 3""",
                fetch_all=True
            )
            
            if category_stats and len(category_stats) > 0:
                report_lines.append("  [ì¸ê¸° ì¹´í…Œê³ ë¦¬ TOP 3]")
                rank_emojis = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"]
                for idx, stat in enumerate(category_stats):
                    category = stat['category']
                    count = stat['count']
                    views = stat['total_views']
                    emoji = rank_emojis[idx] if idx < 3 else f"{idx+1}."
                    report_lines.append(f"    {emoji} {category:8} â”‚ {count:>3}ê°œ ê²Œì‹œê¸€ â”‚ {format_number(views):>6} ì¡°íšŒ")
                report_lines.append("")
                report_lines.append("  ğŸ’¡ ìì„¸í•œ ë‚´ìš©: /trends")
                report_lines.append("")
            else:
                report_lines.append("  â³ ì•„ì§ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                report_lines.append("")
                report_lines.append("  ğŸ’¡ ìì„¸í•œ ë‚´ìš©: /trends")
                report_lines.append("")
            
        except Exception as e:
            report_lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            report_lines.append("â”‚  ğŸ“ˆ ì»¤ë®¤ë‹ˆí‹° íŠ¸ë Œë“œ ë¶„ì„                        â”‚")
            report_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            report_lines.append("")
            report_lines.append(f"  âš ï¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            report_lines.append("")
        
        # ë§ˆë¬´ë¦¬
        report_lines.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append("â•‘              âœ¨ ì˜¤ëŠ˜ë„ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! âœ¨        â•‘")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append("â•‘  ê° ì„¹ì…˜ì˜ ìƒì„¸ ì •ë³´ëŠ” í•´ë‹¹ í˜ì´ì§€ì—ì„œ í™•ì¸:      â•‘")
        report_lines.append("â•‘  â€¢ ì‹ ê³  ê´€ë¦¬: /admin/reports                      â•‘")
        report_lines.append("â•‘  â€¢ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸: /ethics_dashboard                 â•‘")
        report_lines.append("â•‘  â€¢ ì´íƒˆ ë¶„ì„: /churn                              â•‘")
        report_lines.append("â•‘  â€¢ íŠ¸ë Œë“œ: /trends                                â•‘")
        report_lines.append("â•‘                                                   â•‘")
        report_lines.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return "\n".join(report_lines)
        
    except Exception as e:
        return f"""ğŸ“‹ ì˜¤ëŠ˜ì˜ ì¼ì¼ ë³´ê³ ì„œ

âš ï¸ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}

ê° ì„¹ì…˜ì˜ ìƒì„¸ ì •ë³´ëŠ” ë‹¤ìŒ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”:
â€¢ ì‹ ê³  í˜„í™©: /admin/reports
â€¢ ë¹„ìœ¤ë¦¬/ìŠ¤íŒ¸: /ethics_dashboard
â€¢ ì´íƒˆ ë¶„ì„: /churn
â€¢ íŠ¸ë Œë“œ: /trends"""


# ëª¨ë“  ë„êµ¬ ë¦¬ìŠ¤íŠ¸
AGENT_TOOLS = [
    semantic_search_tool,
    churn_analysis_tool,
    ethics_check_tool,
    match_reports_tool,
    trends_analysis_tool,
    execute_churn_analysis_tool,
    execute_ethics_analysis_tool,
    approve_report_tool,
    reject_report_tool,
    filter_reports_tool,
    board_navigation_tool,
    board_detail_tool,
    board_filter_tool,
    board_page_tool,
    board_list_tool,
    daily_report_tool  # ì¼ì¼ ë³´ê³ ì„œ ìƒì„±
]

