"""
ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ì„ ì„ë² ë”©í•˜ì—¬ ChromaDBì— ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‹¤í–‰ ë°©ë²•:
    python embed_board_comments.py

ìš”êµ¬ì‚¬í•­:
    - MySQL DBì— ê²Œì‹œê¸€(board)ê³¼ ëŒ“ê¸€(comment) í…Œì´ë¸” í•„ìš”
    - BGE-M3 ëª¨ë¸ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ)
"""

import os
from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from app.database import execute_query
from agent_back.bge_m3_embeddings import BGEM3Embeddings
from agent_back.semantic_chunker import SemanticChunker
from agent_back.bm25_store import BM25Store

# ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_PATH = Path("chroma_store")

def fetch_boards():
    """DBì—ì„œ exposed ìƒíƒœì˜ ê²Œì‹œê¸€ ê°€ì ¸ì˜¤ê¸°"""
    try:
        query = """
        SELECT b.id, b.title, b.content, b.category, b.created_at, u.username
        FROM board b
        LEFT JOIN users u ON b.user_id = u.id
        WHERE b.status = 'exposed'
        ORDER BY b.created_at DESC
        """
        boards = execute_query(query, fetch_all=True)
        print(f"[OK] ê²Œì‹œê¸€ {len(boards)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        return boards
    except Exception as e:
        print(f"[ERROR] ê²Œì‹œê¸€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def fetch_comments():
    """DBì—ì„œ exposed ìƒíƒœì˜ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°"""
    try:
        query = """
        SELECT c.id, c.content, c.board_id, c.created_at, u.username, b.title as board_title
        FROM comment c
        LEFT JOIN users u ON c.user_id = u.id
        LEFT JOIN board b ON c.board_id = b.id
        WHERE c.status = 'exposed'
        ORDER BY c.created_at DESC
        """
        comments = execute_query(query, fetch_all=True)
        print(f"[OK] ëŒ“ê¸€ {len(comments)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        return comments
    except Exception as e:
        print(f"[ERROR] ëŒ“ê¸€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def create_documents(boards, comments):
    """ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ì„ Document ê°ì²´ë¡œ ë³€í™˜ (SemanticChunker ì ìš©)"""
    documents = []
    
    # SemanticChunker ì´ˆê¸°í™” (ì‚¬ìš©ì ì§€ì • ì„¤ì •ê°’ ì ìš©)
    print("[1/3] SemanticChunker ì´ˆê¸°í™” ì¤‘...")
    chunker = SemanticChunker(
        similarity_threshold=0.75,
        min_chunk_size=80,
        max_chunk_size=1200
    )
    
    print("[2/3] ê²Œì‹œê¸€ ì²­í‚¹ ë° Document ìƒì„± ì¤‘...")
    # ê²Œì‹œê¸€ Document ìƒì„± (ì²­í‚¹ ì ìš©)
    for board in boards:
        # ì œëª©ê³¼ ë‚´ìš©ì„ í•©ì³ì„œ ì²­í‚¹
        full_content = f"ì œëª©: {board['title']}\n\n{board['content']}"
        
        # SemanticChunkerë¡œ ì²­í¬ ë¶„í• 
        chunks = chunker.chunk_text(full_content)
        
        # ê° ì²­í¬ë¥¼ ê°œë³„ Documentë¡œ ìƒì„±
        for chunk_idx, chunk in enumerate(chunks):
            doc = Document(
                page_content=chunk,
                metadata={
                    "id": board['id'],
                    "type": "board",
                    "title": board['title'],
                    "author": board['username'] or 'ìµëª…',
                    "date": str(board['created_at']),
                    "category": board['category'],
                    "chunk_index": chunk_idx,
                    "chunk_count": len(chunks),
                    "chunk_size": len(chunk)
                }
            )
            documents.append(doc)
    
    print("[3/3] ëŒ“ê¸€ Document ìƒì„± ì¤‘...")
    # ëŒ“ê¸€ Document ìƒì„± (ëŒ“ê¸€ì€ ë³´í†µ ì§§ìœ¼ë¯€ë¡œ ì²­í‚¹í•˜ì§€ ì•ŠìŒ)
    for comment in comments:
        # ëŒ“ê¸€ì´ ì¶©ë¶„íˆ ê¸¸ë©´ ì²­í‚¹ ì ìš©
        if len(comment['content']) > 200:
            chunks = chunker.chunk_text(comment['content'])
            for chunk_idx, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "id": comment['id'],
                        "type": "comment",
                        "board_id": comment['board_id'],
                        "board_title": comment['board_title'] or 'ì œëª© ì—†ìŒ',
                        "author": comment['username'] or 'ìµëª…',
                        "date": str(comment['created_at']),
                        "chunk_index": chunk_idx,
                        "chunk_count": len(chunks),
                        "chunk_size": len(chunk)
                    }
                )
                documents.append(doc)
        else:
            # ì§§ì€ ëŒ“ê¸€ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            doc = Document(
                page_content=comment['content'],
                metadata={
                    "id": comment['id'],
                    "type": "comment",
                    "board_id": comment['board_id'],
                    "board_title": comment['board_title'] or 'ì œëª© ì—†ìŒ',
                    "author": comment['username'] or 'ìµëª…',
                    "date": str(comment['created_at']),
                    "chunk_index": 0,
                    "chunk_count": 1,
                    "chunk_size": len(comment['content'])
                }
            )
            documents.append(doc)
    
    print(f"[OK] Document ê°ì²´ {len(documents)}ê°œ ìƒì„± ì™„ë£Œ (ì²­í‚¹ ì ìš©)")
    return documents


def embed_and_store(documents):
    """Documentë¥¼ ì„ë² ë”©í•˜ì—¬ ChromaDBì— ì €ì¥í•˜ê³  BM25 ì¸ë±ìŠ¤ë„ ìƒì„±"""
    try:
        print("\n[1/4] BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        embeddings = BGEM3Embeddings()
        
        print("\n[2/4] ChromaDB ì´ˆê¸°í™” ì¤‘...")
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
        if CHROMA_DB_PATH.exists():
            import shutil
            import time
            import os
            import stat
            print(f"  [WARN] ê¸°ì¡´ ChromaDB ì‚­ì œ ì‹œë„: {CHROMA_DB_PATH}")
            
            # Windowsì—ì„œ íŒŒì¼ ì†ì„± ë³€ê²½ í›„ ì‚­ì œ ì‹œë„
            def remove_readonly(func, path, exc):
                try:
                    os.chmod(path, stat.S_IWRITE)
                    func(path)
                except:
                    pass  # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            try:
                shutil.rmtree(CHROMA_DB_PATH, onerror=remove_readonly)
                print("  [OK] ê¸°ì¡´ ChromaDB ì‚­ì œ ì™„ë£Œ")
            except PermissionError:
                print("  [WARN] íŒŒì¼ì´ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë®ì–´ì“°ê¸° ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ChromaDBê°€ ìë™ìœ¼ë¡œ ë®ì–´ì”€)
        
        CHROMA_DB_PATH.mkdir(parents=True, exist_ok=True)
        
        print(f"\n[3/4] ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì¤‘... (ì´ {len(documents)}ê°œ)")
        print("  ì´ ì‘ì—…ì€ ë¬¸ì„œ ìˆ˜ì— ë”°ë¼ ìˆ˜ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ChromaDBì— ì €ì¥ (ìë™ìœ¼ë¡œ ì„ë² ë”© ìƒì„±)
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=embeddings,
            persist_directory=str(CHROMA_DB_PATH),
            collection_name="board_comments"
        )
        
        print(f"\n[OK] ë²¡í„° ì„ë² ë”© ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ: {CHROMA_DB_PATH}")
        print(f"[OK] ì´ {len(documents)}ê°œ ë¬¸ì„œê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        print(f"\n[4/4] BM25 ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ ì¤‘...")
        # BM25 ì¸ë±ìŠ¤ ìƒì„±
        bm25_store = BM25Store()
        bm25_store.create_bm25_index(documents)
        
        # BM25 ì¸ë±ìŠ¤ ì €ì¥
        bm25_path = CHROMA_DB_PATH / "bm25_index.pkl"
        bm25_store.save_index(str(bm25_path))
        
        print(f"[OK] BM25 ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {bm25_path}")
        
        # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n[í…ŒìŠ¤íŠ¸] 'ìœ¡ì•„' ë²¡í„° ê²€ìƒ‰ ê²°ê³¼:")
        vector_results = vectorstore.similarity_search("ìœ¡ì•„", k=3)
        for idx, doc in enumerate(vector_results, 1):
            doc_type = "ê²Œì‹œê¸€" if doc.metadata['type'] == 'board' else "ëŒ“ê¸€"
            title = doc.metadata.get('title', doc.metadata.get('board_title', 'ì œëª© ì—†ìŒ'))
            chunk_info = f" (ì²­í¬ {doc.metadata.get('chunk_index', 0)+1}/{doc.metadata.get('chunk_count', 1)})" if doc.metadata.get('chunk_count', 1) > 1 else ""
            print(f"  {idx}. [{doc_type}] {title}{chunk_info}")
            print(f"     ë‚´ìš©: {doc.page_content[:50]}...")
        
        print("\n[í…ŒìŠ¤íŠ¸] 'ìœ¡ì•„' BM25 ê²€ìƒ‰ ê²°ê³¼:")
        bm25_results = bm25_store.search("ìœ¡ì•„", k=3)
        for idx, (doc, score) in enumerate(bm25_results, 1):
            doc_type = "ê²Œì‹œê¸€" if doc.metadata['type'] == 'board' else "ëŒ“ê¸€"
            title = doc.metadata.get('title', doc.metadata.get('board_title', 'ì œëª© ì—†ìŒ'))
            chunk_info = f" (ì²­í¬ {doc.metadata.get('chunk_index', 0)+1}/{doc.metadata.get('chunk_count', 1)})" if doc.metadata.get('chunk_count', 1) > 1 else ""
            print(f"  {idx}. [{doc_type}] {title}{chunk_info} (ì ìˆ˜: {score:.3f})")
            print(f"     ë‚´ìš©: {doc.page_content[:50]}...")
        
        # Rerank í…ŒìŠ¤íŠ¸ ì¶”ê°€
        try:
            print("\n[í…ŒìŠ¤íŠ¸] BGE Reranker ì„±ëŠ¥ ë¹„êµ:")
            print("="*60)
            from agent_back.reranker import BGEReranker
            
            reranker = BGEReranker()
            test_query = "ìœ¡ì•„"
            
            # Vector ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ 10ê°œ ê°€ì ¸ì˜¤ê¸°
            candidates = vectorstore.similarity_search(test_query, k=10)
            
            print(f"\n[Before Rerank] Vector ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 5ê°œ):")
            for idx, doc in enumerate(candidates[:5], 1):
                doc_type = "ê²Œì‹œê¸€" if doc.metadata['type'] == 'board' else "ëŒ“ê¸€"
                title = doc.metadata.get('title', doc.metadata.get('board_title', 'ì œëª© ì—†ìŒ'))
                chunk_info = f" (ì²­í¬ {doc.metadata.get('chunk_index', 0)+1}/{doc.metadata.get('chunk_count', 1)})" if doc.metadata.get('chunk_count', 1) > 1 else ""
                print(f"  {idx}. [{doc_type}] {title}{chunk_info}")
                print(f"     ë‚´ìš©: {doc.page_content[:80]}...")
            
            # Rerank ì ìš©
            reranked = reranker.rerank(test_query, candidates, top_k=5)
            
            print(f"\n[After Rerank] Rerank ì ìš© ê²°ê³¼ (ìƒìœ„ 5ê°œ):")
            for idx, (doc, rerank_score) in enumerate(reranked, 1):
                doc_type = "ê²Œì‹œê¸€" if doc.metadata['type'] == 'board' else "ëŒ“ê¸€"
                title = doc.metadata.get('title', doc.metadata.get('board_title', 'ì œëª© ì—†ìŒ'))
                chunk_info = f" (ì²­í¬ {doc.metadata.get('chunk_index', 0)+1}/{doc.metadata.get('chunk_count', 1)})" if doc.metadata.get('chunk_count', 1) > 1 else ""
                print(f"  {idx}. [{doc_type}] {title}{chunk_info} (Rerank ì ìˆ˜: {rerank_score:.4f})")
                print(f"     ë‚´ìš©: {doc.page_content[:80]}...")
            
            print("\n" + "="*60)
            print("[OK] Reranker í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print("="*60)
            print("ğŸ’¡ RerankerëŠ” ì¿¼ë¦¬ì™€ ë¬¸ì„œì˜ ì§ì ‘ì ì¸ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì—¬")
            print("   ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœì„œë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.")
            print("   ì‹¤ì œ ê²€ìƒ‰ ì‹œì—ëŠ” ìë™ìœ¼ë¡œ Rerankê°€ ì ìš©ë©ë‹ˆë‹¤.")
            
        except Exception as rerank_error:
            print(f"\n[WARN] Reranker í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {rerank_error}")
            print("RerankerëŠ” ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ ê¸°ë³¸ ê²€ìƒ‰ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        
        return vectorstore
        
    except Exception as e:
        print(f"\n[ERROR] ì„ë² ë”©/ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*60)
    print("ê²Œì‹œê¸€/ëŒ“ê¸€ ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    print("="*60)
    
    # 1. DBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    print("\n[Step 1] ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ ì¡°íšŒ ì¤‘...")
    boards = fetch_boards()
    comments = fetch_comments()
    
    if len(boards) == 0 and len(comments) == 0:
        print("\n[WARN] ì„ë² ë”©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ê²Œì‹œê¸€ì´ë‚˜ ëŒ“ê¸€ì„ ë¨¼ì € ì‘ì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. Document ê°ì²´ ìƒì„±
    print("\n[Step 2] Document ê°ì²´ ìƒì„± ì¤‘...")
    documents = create_documents(boards, comments)
    
    # 3. ì„ë² ë”© ìƒì„± ë° ì €ì¥
    print("\n[Step 3] ì„ë² ë”© ìƒì„± ë° ChromaDB ì €ì¥ ì¤‘...")
    vectorstore = embed_and_store(documents)
    
    if vectorstore:
        print("\n" + "="*60)
        print("[SUCCESS] ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
        print("="*60)
        print(f"ì €ì¥ ìœ„ì¹˜: {CHROMA_DB_PATH.absolute()}")
        print(f"ê²Œì‹œê¸€: {len(boards)}ê°œ")
        print(f"ëŒ“ê¸€: {len(comments)}ê°œ")
        print(f"ì´ ë¬¸ì„œ: {len(documents)}ê°œ")
        print("\nì´ì œ Agent Chatbotì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("ì„œë²„ ì‹¤í–‰: python run_server.py")
    else:
        print("\n[FAILED] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")


if __name__ == "__main__":
    main()

